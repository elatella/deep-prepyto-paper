<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Amin Khosrozadeh" />
  <meta name="author" content="Raphaela Seeger" />
  <meta name="author" content="Julika Radecke" />
  <meta name="author" content="Guillaume Witz" />
  <meta name="author" content="Jakob B. Sørensen" />
  <meta name="author" content="Benoît Zuber" />
  <meta name="dcterms.date" content="2022-11-22" />
  <meta name="keywords" content="synapse, cryo-electron tomography, synaptic vesicles, deep learning, segmentation, post-processing, automation" />
  <title>Deep-learning based automatic segmentation of vesicles in cryo-electron tomograms</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <!--
  Manubot generated metadata rendered from header-includes-template.html.
  Suggest improvements at https://github.com/manubot/manubot/blob/main/manubot/process/header-includes-template.html
  -->
  <meta name="dc.format" content="text/html" />
  <meta property="og:type" content="article" />
  <meta name="dc.title" content="Deep-learning based automatic segmentation of vesicles in cryo-electron tomograms" />
  <meta name="citation_title" content="Deep-learning based automatic segmentation of vesicles in cryo-electron tomograms" />
  <meta property="og:title" content="Deep-learning based automatic segmentation of vesicles in cryo-electron tomograms" />
  <meta property="twitter:title" content="Deep-learning based automatic segmentation of vesicles in cryo-electron tomograms" />
  <meta name="dc.date" content="2022-11-22" />
  <meta name="citation_publication_date" content="2022-11-22" />
  <meta property="article:published_time" content="2022-11-22" />
  <meta name="dc.modified" content="2022-11-22T14:20:16+00:00" />
  <meta property="article:modified_time" content="2022-11-22T14:20:16+00:00" />
  <meta name="dc.language" content="en-US" />
  <meta name="citation_language" content="en-US" />
  <meta name="dc.relation.ispartof" content="Manubot" />
  <meta name="dc.publisher" content="Manubot" />
  <meta name="citation_journal_title" content="Manubot" />
  <meta name="citation_technical_report_institution" content="Manubot" />
  <meta name="citation_author" content="Amin Khosrozadeh" />
  <meta name="citation_author_institution" content="Institute of Anatomy, University of Bern, Bern, Switzerland" />
  <meta name="citation_author_institution" content="Graduate School for Cellular and Biomedical Sciences, University of Bern" />
  <meta name="citation_author_orcid" content="XXXX-XXXX-XXXX-XXXX" />
  <meta name="citation_author" content="Raphaela Seeger" />
  <meta name="citation_author_institution" content="Institute of Anatomy, University of Bern, Bern, Switzerland" />
  <meta name="citation_author_institution" content="Graduate School for Cellular and Biomedical Sciences, University of Bern" />
  <meta name="citation_author_orcid" content="XXXX-XXXX-XXXX-XXXX" />
  <meta name="citation_author" content="Julika Radecke" />
  <meta name="citation_author_institution" content="Institute of Anatomy, University of Bern, Bern, Switzerland" />
  <meta name="citation_author_institution" content="Department of Neuroscience, Faculty of Health and Medical Science , 2200 Copenhagen N, University of Copenhagen, Copenhagen, Denmark" />
  <meta name="citation_author_institution" content="Diamond Light Source Ltd, Didcot, Oxfordshire, United Kingdom" />
  <meta name="citation_author_orcid" content="0000-0002-5815-5537" />
  <meta name="citation_author" content="Guillaume Witz" />
  <meta name="citation_author_institution" content="Science IT Service, University of Bern, Bern, Switzerland" />
  <meta name="citation_author_institution" content="Microscopy Imaging Center, University of Bern, Bern, Switzerland" />
  <meta name="citation_author_orcid" content="0000-0003-1562-4265" />
  <meta name="citation_author" content="Jakob B. Sørensen" />
  <meta name="citation_author_institution" content="Department of Neuroscience, University of Copenhagen, Blegdamsvej 3B, 2200 Copenhagen N, Denmark" />
  <meta name="citation_author_orcid" content="0000-0001-5465-3769" />
  <meta name="citation_author" content="Benoît Zuber" />
  <meta name="citation_author_institution" content="Institute of Anatomy, University of Bern, Bern, Switzerland" />
  <meta name="citation_author_orcid" content="0000-0001-7725-5579" />
  <link rel="canonical" href="https://elatella.github.io/deep-prepyto-paper/" />
  <meta property="og:url" content="https://elatella.github.io/deep-prepyto-paper/" />
  <meta property="twitter:url" content="https://elatella.github.io/deep-prepyto-paper/" />
  <meta name="citation_fulltext_html_url" content="https://elatella.github.io/deep-prepyto-paper/" />
  <meta name="citation_pdf_url" content="https://elatella.github.io/deep-prepyto-paper/manuscript.pdf" />
  <link rel="alternate" type="application/pdf" href="https://elatella.github.io/deep-prepyto-paper/manuscript.pdf" />
  <link rel="alternate" type="text/html" href="https://elatella.github.io/deep-prepyto-paper/v/bf5b22bccd978715025f0f78380db9692fcfd0e2/" />
  <meta name="manubot_html_url_versioned" content="https://elatella.github.io/deep-prepyto-paper/v/bf5b22bccd978715025f0f78380db9692fcfd0e2/" />
  <meta name="manubot_pdf_url_versioned" content="https://elatella.github.io/deep-prepyto-paper/v/bf5b22bccd978715025f0f78380db9692fcfd0e2/manuscript.pdf" />
  <meta property="og:type" content="article" />
  <meta property="twitter:card" content="summary_large_image" />
  <link rel="icon" type="image/png" sizes="192x192" href="https://manubot.org/favicon-192x192.png" />
  <link rel="mask-icon" href="https://manubot.org/safari-pinned-tab.svg" color="#ad1457" />
  <meta name="theme-color" content="#ad1457" />
  <!-- end Manubot generated metadata -->
  
  <!-- pandoc-eqnos: equation style -->
  <style>
    .eqnos { display: inline-block; position: relative; width: 100%; }
    .eqnos br { display: none; }
    .eqnos-number { position: absolute; right: 0em; top: 50%; line-height: 0; }
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Deep-learning based automatic segmentation of vesicles in cryo-electron tomograms</h1>
</header>
<p><small><em>
This manuscript
(<a href="https://elatella.github.io/deep-prepyto-paper/v/bf5b22bccd978715025f0f78380db9692fcfd0e2/">permalink</a>)
was automatically generated
from <a href="https://github.com/elatella/deep-prepyto-paper/tree/bf5b22bccd978715025f0f78380db9692fcfd0e2">elatella/deep-prepyto-paper@bf5b22b</a>
on November 22, 2022.
</em></small></p>
<h2 id="authors">Authors</h2>
<ul>
<li><p><strong>Amin Khosrozadeh</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/XXXX-XXXX-XXXX-XXXX">XXXX-XXXX-XXXX-XXXX</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/ameen-khosrowzadeh">ameen-khosrowzadeh</a>
<br>
<small>
Institute of Anatomy, University of Bern, Bern, Switzerland; Graduate School for Cellular and Biomedical Sciences, University of Bern
· Funded by Grant XXXXXXXX
</small></p></li>
<li><p><strong>Raphaela Seeger</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/XXXX-XXXX-XXXX-XXXX">XXXX-XXXX-XXXX-XXXX</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/elatella">elatella</a>
<br>
<small>
Institute of Anatomy, University of Bern, Bern, Switzerland; Graduate School for Cellular and Biomedical Sciences, University of Bern
</small></p></li>
<li><p><strong>Julika Radecke</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0002-5815-5537">0000-0002-5815-5537</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/julikaradecke">julikaradecke</a>
<br>
<small>
Institute of Anatomy, University of Bern, Bern, Switzerland; Department of Neuroscience, Faculty of Health and Medical Science , 2200 Copenhagen N, University of Copenhagen, Copenhagen, Denmark; Diamond Light Source Ltd, Didcot, Oxfordshire, United Kingdom
</small></p></li>
<li><p><strong>Guillaume Witz</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0003-1562-4265">0000-0003-1562-4265</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/guiwitz">guiwitz</a>
<br>
<small>
Science IT Service, University of Bern, Bern, Switzerland; Microscopy Imaging Center, University of Bern, Bern, Switzerland
</small></p></li>
<li><p><strong>Jakob B. Sørensen</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-5465-3769">0000-0001-5465-3769</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/JBSorensen">JBSorensen</a>
<br>
<small>
Department of Neuroscience, University of Copenhagen, Blegdamsvej 3B, 2200 Copenhagen N, Denmark
· Funded by Novo Nordisk Fonden, NNF17OC0028516.; Carlsbergfondet, CF17-0875; Independent Research Fond Denmark, 8020-00228A; Lundbeckfonden, R277-2018-802
</small></p></li>
<li><p><strong>Benoît Zuber</strong>
<br>
<img src="images/orcid.svg" class="inline_icon" width="16" height="16" alt="ORCID icon" />
<a href="https://orcid.org/0000-0001-7725-5579">0000-0001-7725-5579</a>
· <img src="images/github.svg" class="inline_icon" width="16" height="16" alt="GitHub icon" />
<a href="https://github.com/aseedb">aseedb</a>
<br>
<small>
Institute of Anatomy, University of Bern, Bern, Switzerland
· Funded by Swiss National Science Foundation, 179520; ERA-NET NEURON, NEURON-119
</small></p></li>
</ul>
<div id="correspondence">
<p>✉ — Correspondence possible via <a href="https://github.com/elatella/deep-prepyto-paper/issues">GitHub Issues</a></p>
</div>
<h2 class="page_break_before" id="abstract">Abstract</h2>
<p>Cryo-electron Tomography (Cryo-ET) has the potential to reveal cell structure down to atomic resolution.
Nevertheless, cellular cryo-ET data is often highly complex and visualization, as well as quantification, of subcellular structures require image segmentation.
Due to a relatively high level of noise and to anisotropic resolution in cryo-ET data, automatic segmentation based on classical computer vision approaches usually does not perform satisfyingly.
For this reason, cryo-ET researchers have mostly performed manual segmentation.</p>
<p>Communication between neurons rely on neurotransmitter-filled synaptic vesicle (SV) exocytosis.
Recruitment of SVs to the plasma membrane is an important means of regulating exocytosis and is influenced by interactions between SVs.
Cryo-ET study of the spatial organization of SVs and of their interconnections allows a better understanding of the mechanisms of exocytosis regulation.
To obtain a faithful representation of SV connectivity state, an absolutely vital prerequisite is an extremely accurate SV segmentation.
Hundreds to thousands of SVs are present in a typical synapse, and their manual segmentation is a burden.
Typically accurately segmenting all SVs in one synapse takes between 3 to 8 days.
<code class="green">Amin: Personaly I do not like this sentcene casue its a bit relative I rather to mention each tomogram contains several hundered vesicles</code>.
This segmentation process has been widely recognized as a bottleneck by the community.</p>
<p>Several attempts to automate vesicle segmentation by classical computer vision or machine learning algorithms have not yielded very robust results.
We addressed this problem by designing a workflow consisting of a U-Net convolutional network followed by post-processing steps.
This combination yields highly accurate results.
Furthermore, we provide an interactive tool for accurately segmenting spherical vesicles in a fraction of the time required by available manual segmentation methods.
This tool can be used to segment vesicles that were missed by the fully automatic procedure or to quickly segment a handful of vesicles, while bypassing the fully automatic procedure.
Our pipeline can in principle be used to segment any spherical vesicle in any cell type as well as extracellular vesicles.</p>
<h2 id="introduction">Introduction</h2>
<p>The fine architecture of cells can be investigated by cryo-electron tomography (cryo-ET) <span class="citation" data-cites="IpfJPPLG">[<a href="#ref-IpfJPPLG" role="doc-biblioref">1</a>]</span>.
Cellular structures are preserved down to the atomic scale through vitrification and observation of the samples in a fully hydrated state.
When a macromolecule is present in a sufficient number of copies in the cells imaged by cryo-ET, it is possible to obtain its atomic structure in situ using subtomogram averaging <span class="citation" data-cites="2TrAHWcN EGfvt7aR">[<a href="#ref-2TrAHWcN" role="doc-biblioref">2</a>,<a href="#ref-EGfvt7aR" role="doc-biblioref">3</a>]</span>.
Cellular cryo-ET datasets are usually extremely complex, making them difficult to analyze.
This is aggravated by the sensitivity of biological samples to electron radiation, which limits the signal-to-noise ratio in cryo-ET datasets <span class="citation" data-cites="WmTa9taa">[<a href="#ref-WmTa9taa" role="doc-biblioref">4</a>]</span>.
Tomographic reconstructions are generated from a series of images of the sample acquired at different viewing angles.
The geometry of the samples prevents acquisition at certain angles, resulting in anisotropic spatial coverage.
The resolution in the directions close to the axis of the electron beam incident on the untilted sample is strongly reduced.
This effect, commonly referred to as the missing-wedge artifact, further complicates data analysis.
In particular, organelles fully bounded by a membrane appear to have holes at their top and bottom (relative to the electron beam axis) <span class="citation" data-cites="WmTa9taa">[<a href="#ref-WmTa9taa" role="doc-biblioref">4</a>]</span>.</p>
<p>The synapse is the functional cellular contact at which information is transmitted from a neuron to another.
The former neuron is called presynaptic and the latter is postsynaptic.
In most cases, the signal is transmitted by the release of neurotransmitters into the intercellular space.
Neurotransmitters are stored in SVs and are released following the fusion of a vesicle with the presynaptic plasma membrane.
A synapse contains hundreds of SVs and their mobility and recruitability for neurotransmitter release depends on inter-vesicle interactions through so-called connector structures <span class="citation" data-cites="XQJ3R1HJ">[<a href="#ref-XQJ3R1HJ" role="doc-biblioref">5</a> ]</span>.
The characterization of these interactions can be performed automatically with the pyto software, which implements a hierarchical connectivity approach to detect and annotate connectors <span class="citation" data-cites="1HtRUUZQi">[<a href="#ref-1HtRUUZQi" role="doc-biblioref">6</a>]</span>. For accurate connector segmentation, an exceptionally precise segmentation of SVs is prerequisite.
To date, this SV segmentation has been achieved manually, but given the massive number of SVs per dataset, it is an extremely time-consuming process.
Typically, one person spends 3 to 8 working days to segment a single dataset.
Attempts to perform this task automatically based on classical computer vision algorithms have not yielded sufficiently accurate performance <span class="citation" data-cites="JWuvfT0Z">[<a href="#ref-JWuvfT0Z" role="doc-biblioref">7</a>]</span>.<br />
To alleviate this situation, we considered applying deep learning methods.</p>
<p>Convolutional neural networks (CNN) have been successfully employed to segment cryo-ET data <span class="citation" data-cites="GNLHO53d">[<a href="#ref-GNLHO53d" role="doc-biblioref">8</a>]</span>.
Although entirely satisfying for visualization purposes, this approach has not met the requirements of pyto.
A recent publication described accurate SV segmentation of transmission electron microscopy images using CNN, but it is limited to 2-dimensional (2D) images of resin-embedded synapses <span class="citation" data-cites="RdPTGoZx">[<a href="#ref-RdPTGoZx" role="doc-biblioref">9</a>]</span>.
In the first study, cryo-ET data are decomposed in individual 2D slices, which are handed as separate input to the CNN.
The independent output 2D prediction images are reassembled in a 3-dimensional(3D) stack.<span class="citation" data-cites="GNLHO53d">[<a href="#ref-GNLHO53d" role="doc-biblioref">8</a>]</span>
As discussed above, membranes oriented approximately parallel to the plane of the 2D tomographic images are not resolved.
In the absence of contextual knowledge of the other 2D images, the CNN fails to segment these regions of the vesicles.
Hence, spherical vesicles appear open, whereas we expect closed spherical objects.
To overcome this limitation, we used a U-Net CNN that takes 3D images as input <span class="citation" data-cites="D7hXMn0y">[<a href="#ref-D7hXMn0y" role="doc-biblioref">10</a>]</span>.
Weigert et al. <span class="citation" data-cites="12G712Zky">[<a href="#ref-12G712Zky" role="doc-biblioref">11</a>]</span> implemented a U-Net for content-aware restoration (CARE) of 3D fluorescence microscopy datasets. They showed that it can restore information from anisotropic and very noisy datasets.
We implemented a 3D U-Net based on CARE building blocks and trained it with manually segmented datasets.
This method provided good accuracy and was only slightly affected by the missing wedge artifact.
Nevertheless, it was not sufficient for our downstream pyto analysis.
Hence, we developed a post-processing method, which transforms the segmented objects into spheres and refines their radius and center location. The procedure includes an outlier detection procedure.
This lead to a substantial accuracy improvement, which are reflected in better pyto performance.
We also introduce a semi-automatic method to very quickly fix wrongly segmented or missed SVs.</p>
<p>Although our set of procedures was developed with the use case of SV segmentation in mind, it can be used to segment any other types of biological spherical vesicles, such as transport vesicles, secretory vesicles, endocytic vesicles, and extracellular vesicles.</p>
<h2 id="results">Results</h2>
<p>Cellular cryo-electron tomography is an upcoming field with a multitude of possible applications.
The manual segmentation of the cellular features is a major bottleneck of this method.
When segmenting cryo-electron tomograms from presynaptic terminals, the manual segmentation of synaptic vesicles is one of the most time-intensive steps.
Synaptic vesicles constitute a large, homogeneous group, constituting a large training set for deep learning applications.
Therefore, we decided to initially develop the automatic segmentation for synaptic vesicles.
The used tomograms were previously manually segmented with IMOD, these manual segmentations were further treated as the ground truth <span class="citation" data-cites="136NHHp17">[<a href="#ref-136NHHp17" role="doc-biblioref">12</a>]</span>.
<code class="green">\_maybe add this somewhere else: In a next step, filaments connecting the synaptic vesicles with each other (connectors) and to the active zone (AZ) were automatically segmented with the algorithm application Pyto [@doi:10.1016/j.jsb.2016.10.004].*</code></p>
<p>The U-Net neural network was used to train its mask prediction on a training set of 9 tomograms containing untreated synaptosomes.
The learning progress was tracked by calculating the Dice coefficient and the loss value after each training epoch (Figure <a href="#fig:dice">1</a>).
The dice value for the training dataset started at a value of ~0.25 and rose to a value of over 0.9 after the initial 50 epoches.
The loss value of the training dataset had an initial value of over 0.55 and declined to values below 0.05 after the initial 50 epochs and further striving towards 0 in the following depicted epochs.
<code>\_Validation Dice and loss from treated synaptosome dataset?*</code>
The validation dataset showed much more fluctuations during both validation and loss progression.
The dice value for the validation dataset started at a value of ~0.27 and rose to an average value of over 0.75 after the initial 50 epoches.
The loss value of the validation dataset had an initial value 1 and declined to values below 0.3 after the initial 50 epochs.</p>
<div id="fig:dice" class="fignos">
<figure>
<img src="images/traindice.png" style="width:7cm" alt="Figure 1: Dice coefficient and loss value for training and validation set. \_legend in figure should say &quot;Training Dice&quot;*" />
<figcaption aria-hidden="true"><span>Figure 1:</span> <strong>Dice coefficient and loss value for training and validation set.</strong> <code class="green">\_legend in figure should say "Training Dice"*</code></figcaption>
</figure>
</div>
<p><code class="green">\_----&gt;add figures of local measurements such as diameter or center error as an extra figure, why else listed in M&amp;M??"*</code></p>
<p>After the neural network is trained to recognize the synaptic vesicles with a sufficient probability, the trained U-Net was implemented into a pipeline.
The pipeline for automatic segmentation of vesicles consists of two major parts: the neural network consisting of a U-Net neural network, and the post-processing steps refining the labels generated by the U-Net (Figure <a href="#fig:pipeline">2</a>).
The three batches of tomograms (synaptosome control, synaptosome treatment and neuron) were each handed to the pipeline.</p>
<div id="fig:pipeline" class="fignos">
<figure>
<img src="images/pipeline.svg" style="width:15cm" alt="Figure 2: Pipeline of automatic segmentation. a) tomograms b) patchify the tomograms into 3D patches c) Segmentation Network/ trained U-Net d) probability masks e) stitching patches back together f) thresholding g) adaptive localized thresholding h) outlier removal i) radial profile" />
<figcaption aria-hidden="true"><span>Figure 2:</span> <strong>Pipeline of automatic segmentation.</strong> a) tomograms b) patchify the tomograms into 3D patches c) Segmentation Network/ trained U-Net d) probability masks e) stitching patches back together f) thresholding g) adaptive localized thresholding h) outlier removal i) radial profile</figcaption>
</figure>
</div>
<p>Each tomogram is split into patches of 32x32x32 <code class="green">\_unit?*</code>.
These patches are the fed into the trained U-Net, which outputs a probability mask for those patches.
To obtain a complete probability mask, the patches are stitched back together.
The probability mask is further refined by applying global and adaptive localized thresholding steps (Figure <a href="#fig:pipeline">2</a>, Figure <a href="#fig:tom">3</a>).</p>
<div id="fig:tom" class="fignos">
<figure>
<img src="images/tomo-sclae.svg" style="width:15cm" alt="Figure 3: 2D Slices A) a section from z axis of a tomogram’s presynaptic terminal of a neuron B) instance mask of the vesicles after post processing; purple corresponds to a low probability of SVs and yellow corresponds to a high probability of synaptic vesicles C) predicted probability mask by the segmentation network" />
<figcaption aria-hidden="true"><span>Figure 3:</span> <strong>2D Slices</strong> A) a section from z axis of a tomogram’s presynaptic terminal of a neuron B) instance mask of the vesicles after post processing; purple corresponds to a low probability of SVs and yellow corresponds to a high probability of synaptic vesicles C) predicted probability mask by the segmentation network</figcaption>
</figure>
</div>
<p><code class="green">\_more detail about global and adaptive localized threshold*</code>
For further optimization of the mask, outliers were removed.
Removed outliers mostly consisted of vesicles which were only partially segmented, and vesicles which maks were adjacent due to proximity.
The removed masks, which only partially traced the vesicles, were reevaluated by reducing or expanding their radius (Figure <a href="#fig:radial_profile">4</a>).
<code class="green">\_was the center of the vesicles also reevaluated?*</code> <code class="green">\_Its not clear or might be false sentence we didnt remove or re evaluate the mask?*</code></p>
<div id="fig:radial_profile" class="fignos">
<figure>
<img src="images/radial_avg_115-099.svg" style="width:15cm" alt="Figure 4: Vesicle radius and position through radial profile and cross-correlation Radial Profile Refinement A) couple of vesicles are not centered B) Radial Profile. Blue range is from membrane center to outer white halo center, this is the search range for the optimal radius. (smoothed by gaussian filtering) C) second derivative of radial profile E, F, H, G) Same as above columns after refinement" />
<figcaption aria-hidden="true"><span>Figure 4:</span> <strong>Vesicle radius and position through radial profile and cross-correlation</strong> Radial Profile Refinement A) couple of vesicles are not centered B) Radial Profile. Blue range is from membrane center to outer white halo center, this is the search range for the optimal radius. (smoothed by gaussian filtering) C) second derivative of radial profile E, F, H, G) Same as above columns after refinement</figcaption>
</figure>
</div>
<p>The adjacent vesicle masks were seperated (Figure <code class="green">\_missing*</code>). <code class="green">\_how?*</code></p>
<p><code class="green">\_**missing Figure- Splitting adjacent vesicles. A) Examples of tomogram, no labels; B) raw label with connected vesicle-labels; C) modified label with seperated vesicles ---&gt; for software: IMOD**</code></p>
<p>The Dice coefficient was used to track the global congruence between the manually segmented mask and the predicted mask within the different tomograms (Figure <a href="#fig:dice-improv">5</a>).</p>
<div id="fig:dice-improv" class="fignos">
<figure>
<img src="images/improvment-post-processing-dice.svg" style="width:15cm" alt="Figure 5: Dice developement during post-processing Dice developement at different post processing steps of initial predicted mask (different colors correspond to different tomograms): A) synaptosomal training datasets B) synaptosomal test datasets c) neuron test datasets" />
<figcaption aria-hidden="true"><span>Figure 5:</span> <strong>Dice developement during post-processing</strong> Dice developement at different post processing steps of initial predicted mask (different colors correspond to different tomograms): A) synaptosomal training datasets B) synaptosomal test datasets c) neuron test datasets</figcaption>
</figure>
</div>
<h3 id="final-eval-tables">Final Eval Tables</h3>
<p>Table 1- Evaluation of the segmentation: Mask Dice: Mask Dice coefficient for the predicted mask; Final Label Dice: Dice coefficient after post-processing; δ d: diameter error on correctly detected vesicle; Δ c: average error center (nm); # of Vesicles: number of expected vesicles; TP: True Positive; FN: False Negative; FP: False Positive</p>
<h4 id="train-dataset">Train Dataset</h4>
<table style="width:100%;">
<colgroup>
<col style="width: 11%" />
<col style="width: 12%" />
<col style="width: 17%" />
<col style="width: 2%" />
<col style="width: 7%" />
<col style="width: 11%" />
<col style="width: 16%" />
<col style="width: 8%" />
<col style="width: 7%" />
<col style="width: 7%" />
</colgroup>
<thead>
<tr class="header">
<th><strong><em>Dataset</em></strong></th>
<th style="text-align: center;"><strong><em>Mask DICE</em></strong></th>
<th style="text-align: center;"><strong><em>Final Label DICE</em></strong></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong><em>δ d</em></strong></th>
<th style="text-align: center;"><strong><em>Δ c (nm)</em></strong></th>
<th style="text-align: center;"><strong><em># of Vesicles</em></strong></th>
<th style="text-align: center;"><strong>TP</strong></th>
<th style="text-align: center;"><strong>FN</strong></th>
<th style="text-align: center;"><strong>FP</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Synaptosome C1</td>
<td style="text-align: center;">0.44</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">2.55±1.56</td>
<td style="text-align: center;">223</td>
<td style="text-align: center;">198</td>
<td style="text-align: center;">26</td>
<td style="text-align: center;">49</td>
</tr>
<tr class="even">
<td>Synaptosome C2</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">2.12±1.06</td>
<td style="text-align: center;">105</td>
<td style="text-align: center;">103</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>Synaptosome C3</td>
<td style="text-align: center;">0.67</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">1.86±1.24</td>
<td style="text-align: center;">128</td>
<td style="text-align: center;">127</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="even">
<td>Synaptosome C4</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.03</td>
<td style="text-align: center;">1.78±0.92</td>
<td style="text-align: center;">144</td>
<td style="text-align: center;">141</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="odd">
<td>Synaptosome C5</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">1.86±1.00</td>
<td style="text-align: center;">214</td>
<td style="text-align: center;">209</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">13</td>
</tr>
<tr class="even">
<td>Synaptosome C6</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.84</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">1.92±1.05</td>
<td style="text-align: center;">104</td>
<td style="text-align: center;">102</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">16</td>
</tr>
<tr class="odd">
<td>Synaptosome C7</td>
<td style="text-align: center;">0.78</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.06</td>
<td style="text-align: center;">1.86±0.90</td>
<td style="text-align: center;">184</td>
<td style="text-align: center;">184</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">16</td>
</tr>
<tr class="even">
<td>Synaptosome C8</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">1.70±0.93</td>
<td style="text-align: center;">132</td>
<td style="text-align: center;">126</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>Synaptosome C9</td>
<td style="text-align: center;">0.59</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">1.87±0.91</td>
<td style="text-align: center;">135</td>
<td style="text-align: center;">132</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">14</td>
</tr>
<tr class="even">
<td><strong>Average</strong></td>
<td style="text-align: center;"><strong>0.64±0.11</strong></td>
<td style="text-align: center;"><strong>0.86±0.05</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>0.05</strong></td>
<td style="text-align: center;"><strong>1.95±1.08</strong></td>
<td style="text-align: center;"><strong>152.22</strong></td>
<td style="text-align: center;"><strong>97.00%</strong></td>
<td style="text-align: center;"><strong>3.00%</strong></td>
<td style="text-align: center;"><strong>7.30%</strong></td>
</tr>
</tbody>
</table>
<h4 id="test-dataset-same-preparation-and-microscope-with-training-set">Test Dataset (Same preparation and microscope with training set)</h4>
<table>
<colgroup>
<col style="width: 11%" />
<col style="width: 11%" />
<col style="width: 17%" />
<col style="width: 2%" />
<col style="width: 7%" />
<col style="width: 11%" />
<col style="width: 15%" />
<col style="width: 7%" />
<col style="width: 7%" />
<col style="width: 7%" />
</colgroup>
<thead>
<tr class="header">
<th><strong><em>Dataset</em></strong></th>
<th style="text-align: center;"><strong><em>Mask DICE</em></strong></th>
<th style="text-align: center;"><strong><em>Final Label DICE</em></strong></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong><em>δ d</em></strong></th>
<th style="text-align: center;"><strong><em>Δ c (nm)</em></strong></th>
<th style="text-align: center;"><strong><em># of Vesicles</em></strong></th>
<th style="text-align: center;"><strong>TP</strong></th>
<th style="text-align: center;"><strong>FN</strong></th>
<th style="text-align: center;"><strong>FP</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Synaptosome C10</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.88</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">1.86±1.18</td>
<td style="text-align: center;">129</td>
<td style="text-align: center;">123</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">5</td>
</tr>
<tr class="even">
<td>Synaptosome T1</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">2.66±1.52</td>
<td style="text-align: center;">699</td>
<td style="text-align: center;">687</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">33</td>
</tr>
<tr class="odd">
<td>Synaptosome T2</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.77</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">2.27±1.84</td>
<td style="text-align: center;">122</td>
<td style="text-align: center;">117</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">2</td>
</tr>
<tr class="even">
<td>Synaptosome T3</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">3.64±2.22</td>
<td style="text-align: center;">434</td>
<td style="text-align: center;">397</td>
<td style="text-align: center;">37</td>
<td style="text-align: center;">57</td>
</tr>
<tr class="odd">
<td>Synaptosome T5</td>
<td style="text-align: center;">0.77</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.08</td>
<td style="text-align: center;">2.20±1.26</td>
<td style="text-align: center;">535</td>
<td style="text-align: center;">526</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">25</td>
</tr>
<tr class="even">
<td>Synaptosome T6</td>
<td style="text-align: center;">0.6</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">2.02±1.12</td>
<td style="text-align: center;">373</td>
<td style="text-align: center;">353</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">42</td>
</tr>
<tr class="odd">
<td>Synaptosome T7</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.06</td>
<td style="text-align: center;">2.22±1.14</td>
<td style="text-align: center;">110</td>
<td style="text-align: center;">107</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">9</td>
</tr>
<tr class="even">
<td>Synaptosome T8</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;">0.91</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">2.09±1.04</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">99</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
</tr>
<tr class="odd">
<td>Synaptosome T10</td>
<td style="text-align: center;">0.77</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">1.96±1.04</td>
<td style="text-align: center;">77</td>
<td style="text-align: center;">74</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="even">
<td><strong>Average</strong></td>
<td style="text-align: center;"><strong>0.75±0.06</strong></td>
<td style="text-align: center;"><strong>0.83±0.05</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>0.08</strong></td>
<td style="text-align: center;"><strong>2.32±1.43</strong></td>
<td style="text-align: center;"><strong>286.56</strong></td>
<td style="text-align: center;"><strong>96.30%</strong></td>
<td style="text-align: center;"><strong>3.70%</strong></td>
<td style="text-align: center;"><strong>6.10%</strong></td>
</tr>
</tbody>
</table>
<h4 id="test-dataset-3-neuron-dataset">Test Dataset 3 (Neuron Dataset)</h4>
<table style="width:100%;">
<colgroup>
<col style="width: 10%" />
<col style="width: 12%" />
<col style="width: 17%" />
<col style="width: 2%" />
<col style="width: 7%" />
<col style="width: 11%" />
<col style="width: 16%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 7%" />
</colgroup>
<thead>
<tr class="header">
<th><strong><em>Dataset</em></strong></th>
<th style="text-align: center;"><strong><em>Mask DICE</em></strong></th>
<th style="text-align: center;"><strong><em>Final Label DICE</em></strong></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong><em>δ d</em></strong></th>
<th style="text-align: center;"><strong><em>Δ c (nm)</em></strong></th>
<th style="text-align: center;"><strong><em># of Vesicles</em></strong></th>
<th style="text-align: center;"><strong>TP</strong></th>
<th style="text-align: center;"><strong>FN</strong></th>
<th style="text-align: center;"><strong>FP</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Neuron 133</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">2.16±1.32</td>
<td style="text-align: center;">523</td>
<td style="text-align: center;">467</td>
<td style="text-align: center;">56</td>
<td style="text-align: center;">8</td>
</tr>
<tr class="even">
<td>Neuron 123</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">0.71</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">2.05±1.18</td>
<td style="text-align: center;">66</td>
<td style="text-align: center;">58</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">2</td>
</tr>
<tr class="odd">
<td>Neuron 84</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">0.89</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.06</td>
<td style="text-align: center;">1.44±0.75</td>
<td style="text-align: center;">498</td>
<td style="text-align: center;">484</td>
<td style="text-align: center;">14</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="even">
<td>Neuron 134</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.67</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.09</td>
<td style="text-align: center;">2.87±2.50</td>
<td style="text-align: center;">638</td>
<td style="text-align: center;">384</td>
<td style="text-align: center;">254</td>
<td style="text-align: center;">63</td>
</tr>
<tr class="odd">
<td>Neuron 115</td>
<td style="text-align: center;">0.57</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.08</td>
<td style="text-align: center;">3.56±3.23</td>
<td style="text-align: center;">170</td>
<td style="text-align: center;">123</td>
<td style="text-align: center;">47</td>
<td style="text-align: center;">32</td>
</tr>
<tr class="even">
<td>Neuron 102</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.05</td>
<td style="text-align: center;">1.47±0.79</td>
<td style="text-align: center;">103</td>
<td style="text-align: center;">86</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td>Neuron 80</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">0.81</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">2.67±2.00</td>
<td style="text-align: center;">111</td>
<td style="text-align: center;">102</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">3</td>
</tr>
<tr class="even">
<td>Neuron 114</td>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">2.68±1.79</td>
<td style="text-align: center;">131</td>
<td style="text-align: center;">93</td>
<td style="text-align: center;">38</td>
<td style="text-align: center;">9</td>
</tr>
<tr class="odd">
<td>Neuron 132</td>
<td style="text-align: center;">0.69</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.03</td>
<td style="text-align: center;">1.65±1.26</td>
<td style="text-align: center;">135</td>
<td style="text-align: center;">129</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">32</td>
</tr>
<tr class="even">
<td>Neuron 73</td>
<td style="text-align: center;">0.78</td>
<td style="text-align: center;">0.83</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.06</td>
<td style="text-align: center;">2.93±2.00</td>
<td style="text-align: center;">526</td>
<td style="text-align: center;">483</td>
<td style="text-align: center;">43</td>
<td style="text-align: center;">2</td>
</tr>
<tr class="odd">
<td>Neuron 128</td>
<td style="text-align: center;">0.67</td>
<td style="text-align: center;">0.85</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.04</td>
<td style="text-align: center;">2.33±1.70</td>
<td style="text-align: center;">252</td>
<td style="text-align: center;">232</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">19</td>
</tr>
<tr class="even">
<td>Neuron 116</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">0.07</td>
<td style="text-align: center;">2.38±1.82</td>
<td style="text-align: center;">296</td>
<td style="text-align: center;">207</td>
<td style="text-align: center;">89</td>
<td style="text-align: center;">35</td>
</tr>
<tr class="odd">
<td><strong>Average</strong></td>
<td style="text-align: center;"><strong>0.69±0.09</strong></td>
<td style="text-align: center;"><strong>0.79±0.09</strong></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"><strong>0.06</strong></td>
<td style="text-align: center;"><strong>2.35±1.83</strong></td>
<td style="text-align: center;"><strong>287.42</strong></td>
<td style="text-align: center;"><strong>83.60%</strong></td>
<td style="text-align: center;"><strong>16.40%</strong></td>
<td style="text-align: center;"><strong>7.90%</strong></td>
</tr>
</tbody>
</table>
<p>Our method transfers well across datasets even without fine-tuning which show robustness and generalization.</p>
<h3 id="comparison-of-manual-segmentation-with-automatic-deep-learning-based-segmentation">Comparison of manual segmentation with automatic deep-learning based segmentation</h3>
<div id="fig:3d" class="fignos">
<figure>
<img src="images/3d.png" style="width:10cm" alt="Figure 6: 3D model of manual segmented and automatically segmented synaptosome." />
<figcaption aria-hidden="true"><span>Figure 6:</span> <strong>3D model of manual segmented and automatically segmented synaptosome.</strong></figcaption>
</figure>
</div>
<h2 id="discussion">Discussion</h2>
<p>While the Dice coefficient is a good global measure to assess the predictions in comparison to the ground truth, it is difficult to asses local segmentation accurracy.
For example, a single generated vesicle label containing several close connected vesicles would not be practical for further analysis for the researcher although it could have almost the same dice value.
What is important for actual usage of the software would be the number and percentage of true-detected vesicles, false-positive and false-negative rates.</p>
<p>Center error:
If we measure each axis error it will reveal that human bias in segmentation is more affected on the Z-axis. [we didn’t show it in number but its checked the hypothesis]
<code class="green">\_we cannot claim something without showing it. ---&gt; this would belong into results*</code></p>
<p>3d unet good for 3D processing
recent Nature methods paper by Ben Engel, DeepFinder -&gt; Relion for STA creates mask to find more using dl
-what are they doing, maybe compare that in the text, different aims; we might compare results we achieve (keep as bonus, revision)</p>
<h3 id="outlook">Outlook</h3>
<p>implement automatic cell-outline and active zone segmentation as deep learning workflow using UNet
implement automatic connector and tether segmentation as a deep leaning workflow using UNet</p>
<h2 id="materials-and-methods">Materials and methods</h2>
<h3 id="cryo-electron-tomography-datasets">Cryo-electron Tomography Datasets</h3>
<p>Two datasets of different origin were used as input and test subjects for the automatic segmentation pipeline, respectively.
They consisted in rat synaptosomes primary neuron cultures derived from mice.
The preparation procedure of the samples from which the datasets were obtained as well as the biological analysis of these datasets was previously reported <span class="citation" data-cites="CERJ8H0p">[<a href="#ref-CERJ8H0p" role="doc-biblioref">13</a>]</span>.</p>
<h3 id="manual-segmentation-and-automatic-interboundary-segment-detection">Manual segmentation and automatic interboundary segment detection</h3>
<p>Manual segmentation of SVs, mitochondria, the active zone PM, and of the segmentation region was done in IMOD (???Figure S4A&amp;B???) <span class="citation" data-cites="136NHHp17">[<a href="#ref-136NHHp17" role="doc-biblioref">12</a>]</span>. SVs were segmented as spheres.
The segmentation region marked the region to be analyzed by Pyto <span class="citation" data-cites="1HtRUUZQi">[<a href="#ref-1HtRUUZQi" role="doc-biblioref">6</a>]</span>.
The analysis by Pyto was essentially the same as described previously <span class="citation" data-cites="XQJ3R1HJ 1HtRUUZQi">[<a href="#ref-XQJ3R1HJ" role="doc-biblioref">5</a>,<a href="#ref-1HtRUUZQi" role="doc-biblioref">6</a>]</span>.
In short, the segmented region is divided in 1 voxel thick layers parallel to the active zone for distance calculations.
A hierarchical connectivity segmentation detects densities interconnecting boundaries.
The boundaries were synaptic vesicles and the active zone PM. Detected intervesicular segments are termed connectors and segments connecting vesicles to the active zone PM are called tethers (Figure <code class="green">\_add figure number*</code>).
Distance calculations respective to SVs were done from SV center.
The segmentation procedure is conservative and tends to miss some tethers and connectors because of noise.
Consequently, the numbers of tethers and connectors should not be considered as absolute values, but rather to compare experimental groups.
As it was done before, an upper limit was set between 2100 and 3200 nm<sup>3</sup> on segment volume.
The tomograms that were used for this analysis were binned by a factor of 2 to 3, resulting in voxel sizes between 2.1 and 2.4 nm.</p>
<h3 id="pre-processing-of-manual-segmentation-outputs-from-imod-for-further-use-jupyter-notebook-pre-pyto">Pre-processing of manual segmentation outputs from IMOD for further use (jupyter notebook pre-pyto)</h3>
<p><code>probably not necessary to mention output from IMOD to prepyto input label file procedure</code></p>
<p><code class="green">put this somewhere else</code>
The used datasets included a total of 30 tomograms with heterogeneous pixel sizes, defocus and resolution.</p>
<ol type="1">
<li>9 synaptosome datasets were used for training and validation.</li>
<li>9 synaptosome datasets was used for test.</li>
<li>12 Neuron dataset were used for assessing transfer learning potential.</li>
</ol>
<h3 id="network-architecture-and-training-procedure">Network architecture and training procedure</h3>
<p>We used a U-Net of depth 2, two convolutional layers per depth, a convolutional kernel size of 3, and ReLU activation function based on the open-source CARE framework (Figure <a href="#fig:unet">7</a>) <span class="citation" data-cites="12G712Zky">[<a href="#ref-12G712Zky" role="doc-biblioref">11</a>]</span>.
Datasets were prepared by splitting the 3D tomographic volume of synaptosomes into 32<sup>3</sup>-voxel subvolumes and keeping only subvolumes occupied by a sufficient amount (&gt; 1000 voxels) of binarized vesicle label.
860 subvolumes were used for training and 100 subvolumes were used for validation.
We used the Adam optimizer on a binary cross-entropy loss function.</p>
<div id="fig:unet" class="fignos">
<figure>
<img src="images/unet.png" style="width:10cm" alt="Figure 7: Network architecture used for vesicle segmentation. We used a U-Net based on the CARE framework [11]. The input is a cubic volume of 323 voxels. The output is a per-prix probabilty cube of the same size as the input." />
<figcaption aria-hidden="true"><span>Figure 7:</span> <strong>Network architecture used for vesicle segmentation.</strong> We used a U-Net based on the CARE framework <span class="citation" data-cites="12G712Zky">[<a href="#ref-12G712Zky" role="doc-biblioref">11</a>]</span>. The input is a cubic volume of 32<sup>3</sup> voxels. The output is a per-prix probabilty cube of the same size as the input.</figcaption>
</figure>
</div>
<h3 id="u-net-output-threshold-refinement">U-Net output threshold refinement</h3>
<p>The probability mask output by the U-Net was first made binary by determining a global threshold value. To this end, the mask was binarized for a range of threshold values comprised between 0.8 and 1. For each probability value a 1-voxel thick label shell was computed.
The shell mask was then applied on the input data and the average masked voxel intensity was computed.
Since the shell of correctly segmented vesicles corresponds to the vesicle membrane, we expect low intensity pixels.
The threshold value resulting in the minimal average intensity of the shell masked voxels was used as the global threshold.<br />
<code class="green">Amin please write the equations for these steps</code>.
The probability mask was binarized using the global threshold and was each separate segment was assigned an individual label with <code>scikit-image label</code> method.</p>
<p>A majority of vesicles were correctly segmented but we noticed some segments included two vesicles.
We therefore evaluated each segment with two criteria based on the fact that synaptic vesicles have a homogenous size and are spherical.
Firstly we calculated the volume z-score <span class="math inline">\(z\)</span> for each segment:
<span id="eq:z-score-volume" class="eqnos"><span class="math display">\[z(S_i) = \frac{V(S_i) - \mu}{\sigma}\]</span><span class="eqnos-number">(1)</span></span>
where <span class="math inline">\(S_i\)</span> is the segment <span class="math inline">\(i\)</span>, <span class="math inline">\(V(S_i)\)</span> is the volume of <span class="math inline">\(S_i\)</span>, <span class="math inline">\(\mu\)</span> the average volume of all segments, and <span class="math inline">\(\sigma\)</span> the standard deviation of the segment volumes.
Secondly, we computed the segment extent <span class="math inline">\(e\)</span>:
<span id="eq:extent" class="eqnos"><span class="math display">\[e(S_i) = \frac{V(S_i)}{B(S_i)}\]</span><span class="eqnos-number">(2)</span></span>
where <span class="math inline">\(B(S_i)\)</span> is the volume of segment <span class="math inline">\(i\)</span> bounding box.
The extent of a sphere equals <span class="math inline">\(\frac{\pi}{6}\)</span>.
Segments with both a z-score <span class="math inline">\(z &gt; 1\)</span> and an extent <span class="math inline">\(e &lt; 0.25\)</span> were considered as potentially comprising two vesicles.
For each of these segments, the probability mask threshold was increased until two distinct segments were generated.
Subsequently, the extent and volume of all segments was evaluated again. Any segment with <span class="math inline">\(e &lt; 0.25\)</span>, or <span class="math inline">\(e &gt; 0.75\)</span>, or <span class="math inline">\(V &lt; k\)</span> was discarded.
This ensured that segments deviating highly from spherical shape and segments with a volume smaller than an acceptable volume <span class="math inline">\(k\)</span> were removed.</p>
<p>Even if most synaptic vesicles were detected and well segmented, segmentation accuracy was not sufficient for our downstream application.
To improve accuracy, each segment was converted to a spherical segment and its radius and position was refined.
Initial spherical conversion was done by setting the center of the sphere <span class="math inline">\(C\)</span> at the position of the centroid of the segment, while the radius <span class="math inline">\(r\)</span> was defined as half the length of the bounding box longest edge.
The segment position and radius was iteratively refined as follows.
1. The radial average <span class="math inline">\(\langle I(d)\rangle\)</span> was computed:
<span id="eq:radial_average" class="eqnos"><span class="math display">\[\langle I(d)\rangle = \frac{1}{4\pi ^2 r^2} \int_{0}^{2\pi}\int_{0}^{2\pi}I(d,\theta ,\phi) \, d\phi \, d\theta\]</span><span class="eqnos-number">(3)</span></span>
where <span class="math inline">\(d\)</span> is the radial distance from the segment center, <span class="math inline">\(\theta\)</span> the polar angle, and <span class="math inline">\(\phi\)</span> the azimuthal angle.
2. The radius of the vesicle <span class="math inline">\(r\)</span> was updated as:
<span id="eq:vesicle_radius" class="eqnos"><span class="math display">\[r = d_m + \frac{t_m}{2}\]</span><span class="eqnos-number">(4)</span></span>
where <span class="math inline">\(d_m\)</span> is the radial distance of center of the vesicle membrane, and <span class="math inline">\(t_m\)</span> the thickness of the vesicle membrane.
<span class="math inline">\(d_m\)</span> was defined as the radial distance for which the radial average was minimal.
<span class="math inline">\(\frac{t_m}{2}\)</span> was calculated as the distance between the center of the vesicle membrane and the minimum of the second derivative of the radial profile in the interval between the center of the vesicle membrane and the maximum of the Fresnel fringe outside the membrane.
3. The radial average was back projected in 3-dimension:
<span id="eq:3d-average" class="eqnos"><span class="math display">\[I(x,y,z) =  \langle I(\sqrt{x^2+y^2+z^2})\rangle\]</span><span class="eqnos-number">(5)</span></span>
where <span class="math inline">\((x,y,z)=(0,0,0)\)</span> is the coordinate of the segment center.
4. We computed by cross-correlation the shift between the obtained 3-D average and the 3-D image in the cubic box with central coordinates <span class="math inline">\(C\)</span> and edge length <span class="math inline">\(l = 2r + c\)</span>, where <span class="math inline">\(c\)</span> is a constant.
<span class="math inline">\(C\)</span> was updated by subtraction of the shift.
5. Steps 1 to 4 were repeated for a maximum of 10 iterations until convergence or until a total shift of <span class="math inline">\(\frac{1}{2}\sqrt{3l_o^2}\)</span>, where $l_o is the edge length of the initial box.
The feature space of predicted vesicle labels was computed, containing membrane thickness <span class="math inline">\(t_m\)</span>, membrane intensity <span class="math inline">\(\rho\)</span>, and vesicle radius <span class="math inline">\(r\)</span>.
<span class="math inline">\(\rho\)</span> was defined as the mean intensity of the radial average within the radial distance interval <span class="math inline">\([d_m - \frac{t_m}{2}\,,\,d_m + \frac{t_m}{2}]\)</span>.</p>
<p>Using this multivariate feature space, we detect outliers by computing Mahalanobis Distances (MD) on normalized variables using the covariance matrix of observation and obtaining The p-value of MD.
<code class="yellow">The sphere segments with a p-value higher than a defined threshold were discarded and the process was repeated iteratively. If the MD p-value of a specific vesicle was not in a specific margin range (0-10), their radial profile was recalculated, and the label entirely removed if they again failed to pass the margin of the p-value.</code>
<code class="green">Amin, please check what exactly was done with the outliers.  And p-value cannot be higher than 1, while you wrote (0-10)</code></p>
<h3 id="analysis-of-results">Analysis of Results</h3>
<p>The evaluation framework was designed to assess the capabilities of the proposed toolbox for automatic synaptic vesicle segmentation.
The framework was not only designed to evaluate quantitatively performance of the neural network, but rather assay the segmentation of vesicles in practice <code class="green">\_unsure what the last part means*</code>. <code class="green">\_I tried to say we develop the software rather than an algorithm paper with ablation study kinda more trasnfer learning but however for tranfer learning we might need add finetunning the network or say this sentence in other way*</code>.
The pipeline also generates a specific output format, which is necessary to further analyze the presynaptic tomograms via another pre-developed toolbox (Pyto), which segments small molecular filaments associated to the synaptic vesicles, titled tethers and connectors.</p>
<h4 id="dice">DICE</h4>
<p>The <code class="green">\_general form??*</code> DICE coefficient for probabilistic subvolume maps was calculated after each epoch as a performance quantification while <code class="green">\_during?*</code> training.
The probabilistic mask subvolumes were stitched back together, creating a probabilistic map of the whole tomogram.
The Soft-DICE for the whole tomogram was calculated to evaluate the similarity of the predicted probability mask with ground truth.
Note that soft-dice is equivalent to dice, when the input is binarized (which we will do at the end of the post-processing).</p>
<p><span class="math display">\[1-\frac{2\sum_{pixels} y_{true} y_{pred}%}{\sum_{pixels} y_{true}^2+\sum_{pixels} y_{pred}^2}\]</span></p>
<p><code class="green">\_shouln't it be voxels instead of pixels??*</code>
<code class="green">\_yes voxel is right*</code></p>
<p>THE DICE was also employed to monitor all stages of post-processing on the eventual label file, to observe the effect of each post-processing step.</p>
<h4 id="diameter-error">Diameter Error</h4>
<p>The diameter of a vesicle is one of its relevant characterizations, and it is predefined (see Outlier Removal).
<code class="green">\_which diameters are we using in this evaluation as input, pre- or post-outlier removal?*</code>
<code class="green">\_after! I meant from that perentesis that radius or dimater we assume as one charectiristic of vesicle we might can write it better *</code>
The error of diameter estimation of true-detected vesicle is defined as 1 minus the proportion of diameters</p>
<p><span id="eq:regular-equation" class="eqnos"><span class="math display">\[\delta d=1-\frac{min(dSi,dGTi)}{max(dSi,dGTi)}\]</span><span class="eqnos-number">(6)</span></span> </p>
<p>where dGTi is the diameter of each true manual segmented vesicle, and dSi is the diameter of its estimation.</p>
<h4 id="center-error">Center error</h4>
<p>The center error is an euclidean distance of ground truth and corresponds to true predicted vesicles <code class="green">\_true pos or true neg*</code>.
A vesicle was defined as a true-detected vesicle if the predicted center was located inside the hand-segmented vesicle and the other way around the center of prediction was located inside the predicted vesicle.
<code class="green">\_isn't this a bit too general, shouldn't this be a tighter evaluation?*</code>
<code class="green">\_we assume this as hard condition to be true postive we could define like some % liek 50% intersection but this condition is generally harder</code>
This means the volume of intersection of the estimated vesicle with the distance of d to a ground truth vesicle with radius R is:</p>
<p><span class="math display">\[V=\frac{1}{12}\pi(4R+d)(2R-d)\]</span></p>
<h3 id="manuscript-preparation">Manuscript preparation</h3>
<p>The manuscript was written with the open and collaborative scientific writing package Manubot <span class="citation" data-cites="YuJbg3zO">[<a href="#ref-YuJbg3zO" role="doc-biblioref">14</a>]</span>.
The source code and data for this manuscript are available at <a href="https://github.com/aseedb/synaptic_tomo_ms" class="uri">https://github.com/aseedb/synaptic_tomo_ms</a>.</p>
<h2 class="page_break_before" id="references">References</h2>
<!-- Explicitly insert bibliography here -->
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-IpfJPPLG" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline"><strong>Towards Visual Proteomics at High Resolution</strong> <div class="csl-block">Felix JB Bäuerlein, Wolfgang Baumeister</div> <em>Journal of Molecular Biology</em> (2021-10) <a href="https://doi.org/gn9t3v">https://doi.org/gn9t3v</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.jmb.2021.167187">10.1016/j.jmb.2021.167187</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34384780">34384780</a></div></div>
</div>
<div id="ref-2TrAHWcN" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline"><strong>Exploring high-resolution cryo-ET and subtomogram averaging capabilities of contemporary DEDs</strong> <div class="csl-block">Martin Obr, Wim JH Hagen, Robert A Dick, Lingbo Yu, Abhay Kotecha, Florian KM Schur</div> <em>Cold Spring Harbor Laboratory</em> (2022-01-10) <a href="https://doi.org/gn92pd">https://doi.org/gn92pd</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1101/2022.01.10.475481">10.1101/2022.01.10.475481</a></div></div>
</div>
<div id="ref-EGfvt7aR" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline"><strong>High-resolution in situ structure determination by cryo-electron tomography and subtomogram averaging using emClarity</strong> <div class="csl-block">Tao Ni, Thomas Frosio, Luiza Mendonça, Yuewen Sheng, Daniel Clare, Benjamin A Himes, Peijun Zhang</div> <em>Nature Protocols</em> (2022-01-12) <a href="https://doi.org/gn92pc">https://doi.org/gn92pc</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41596-021-00648-5">10.1038/s41596-021-00648-5</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/35022621">35022621</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9251519">PMC9251519</a></div></div>
</div>
<div id="ref-WmTa9taa" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline"><strong>STRUCTURAL STUDIES BY ELECTRON TOMOGRAPHY: From Cells to Molecules</strong> <div class="csl-block">Vladan Lučić, Friedrich Förster, Wolfgang Baumeister</div> <em>Annual Review of Biochemistry</em> (2005-06-01) <a href="https://doi.org/cfd27f">https://doi.org/cfd27f</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1146/annurev.biochem.73.011303.074112">10.1146/annurev.biochem.73.011303.074112</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/15952904">15952904</a></div></div>
</div>
<div id="ref-XQJ3R1HJ" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline"><strong>Quantitative analysis of the native presynaptic cytomatrix by cryoelectron tomography</strong> <div class="csl-block">Rubén Fernández-Busnadiego, Benoît Zuber, Ulrike Elisabeth Maurer, Marek Cyrklaff, Wolfgang Baumeister, Vladan Lučić</div> <em>Journal of Cell Biology</em> (2010-01-11) <a href="https://doi.org/b9c26b">https://doi.org/b9c26b</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1083/jcb.200908082">10.1083/jcb.200908082</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20065095">20065095</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2812849">PMC2812849</a></div></div>
</div>
<div id="ref-1HtRUUZQi" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">6. </div><div class="csl-right-inline"><strong>Hierarchical detection and analysis of macromolecular complexes in cryo-electron tomograms using Pyto software</strong> <div class="csl-block">Vladan Lučić, Rubén Fernández-Busnadiego, Ulrike Laugks, Wolfgang Baumeister</div> <em>Journal of Structural Biology</em> (2016-12) <a href="https://doi.org/f9d5t2">https://doi.org/f9d5t2</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.jsb.2016.10.004">10.1016/j.jsb.2016.10.004</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27742578">27742578</a></div></div>
</div>
<div id="ref-JWuvfT0Z" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">7. </div><div class="csl-right-inline"><strong>Robust membrane detection based on tensor voting for electron tomography</strong> <div class="csl-block">Antonio Martinez-Sanchez, Inmaculada Garcia, Shoh Asano, Vladan Lucic, Jose-Jesus Fernandez</div> <em>Journal of Structural Biology</em> (2014-04) <a href="https://doi.org/f5zkj8">https://doi.org/f5zkj8</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.jsb.2014.02.015">10.1016/j.jsb.2014.02.015</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24625523">24625523</a></div></div>
</div>
<div id="ref-GNLHO53d" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">8. </div><div class="csl-right-inline"><strong>Convolutional neural networks for automated annotation of cellular cryo-electron tomograms</strong> <div class="csl-block">Muyuan Chen, Wei Dai, Stella Y Sun, Darius Jonasch, Cynthia Y He, Michael F Schmid, Wah Chiu, Steven J Ludtke</div> <em>Nature Methods</em> (2017-08-28) <a href="https://doi.org/gkpj62">https://doi.org/gkpj62</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/nmeth.4405">10.1038/nmeth.4405</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28846087">28846087</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5623144">PMC5623144</a></div></div>
</div>
<div id="ref-RdPTGoZx" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">9. </div><div class="csl-right-inline"><strong>Automated Detection and Localization of Synaptic Vesicles in Electron Microscopy Images</strong> <div class="csl-block">Barbara Imbrosci, Dietmar Schmitz, Marta Orlando</div> <em>eneuro</em> (2022-01) <a href="https://doi.org/gn9n8k">https://doi.org/gn9n8k</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1523/eneuro.0400-20.2021">10.1523/eneuro.0400-20.2021</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34983830">34983830</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8805189">PMC8805189</a></div></div>
</div>
<div id="ref-D7hXMn0y" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">10. </div><div class="csl-right-inline"><strong>3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation</strong> <div class="csl-block">Özgün Çiçek, Ahmed Abdulkadir, Soeren S Lienkamp, Thomas Brox, Olaf Ronneberger</div> <em>arXiv</em> (2016-06-22) <a href="https://arxiv.org/abs/1606.06650">https://arxiv.org/abs/1606.06650</a></div>
</div>
<div id="ref-12G712Zky" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">11. </div><div class="csl-right-inline"><strong>Content-aware image restoration: pushing the limits of fluorescence microscopy</strong> <div class="csl-block">Martin Weigert, Uwe Schmidt, Tobias Boothe, Andreas Müller, Alexandr Dibrov, Akanksha Jain, Benjamin Wilhelm, Deborah Schmidt, Coleman Broaddus, Siân Culley, … Eugene W Myers</div> <em>Nature Methods</em> (2018-11-26) <a href="https://doi.org/gfkkfd">https://doi.org/gfkkfd</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41592-018-0216-7">10.1038/s41592-018-0216-7</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30478326">30478326</a></div></div>
</div>
<div id="ref-136NHHp17" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">12. </div><div class="csl-right-inline"><strong>Computer Visualization of Three-Dimensional Image Data Using IMOD</strong> <div class="csl-block">James R Kremer, David N Mastronarde, JRichard McIntosh</div> <em>Journal of Structural Biology</em> (1996-01) <a href="https://doi.org/d9nfzw">https://doi.org/d9nfzw</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1006/jsbi.1996.0013">10.1006/jsbi.1996.0013</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/8742726">8742726</a></div></div>
</div>
<div id="ref-CERJ8H0p" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">13. </div><div class="csl-right-inline"><strong>Morphofunctional changes at the active zone during synaptic vesicle exocytosis</strong> <div class="csl-block">Julika Radecke, Raphaela Seeger, Anna Kádková, Ulrike Laugks, Amin Khosrozadeh, Kenneth N Goldie, Vladan Lučić, Jakob B Sørensen, Benoît Zuber</div> <em>Cold Spring Harbor Laboratory</em> (2022-03-07) <a href="https://doi.org/gpm26v">https://doi.org/gpm26v</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1101/2022.03.07.483217">10.1101/2022.03.07.483217</a></div></div>
</div>
<div id="ref-YuJbg3zO" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">14. </div><div class="csl-right-inline"><strong>Open collaborative writing with Manubot</strong> <div class="csl-block">Daniel S Himmelstein, Vincent Rubinetti, David R Slochower, Dongbo Hu, Venkat S Malladi, Casey S Greene, Anthony Gitter</div> <em>PLOS Computational Biology</em> (2019-06-24) <a href="https://doi.org/c7np">https://doi.org/c7np</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pcbi.1007128">10.1371/journal.pcbi.1007128</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31233491">31233491</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6611653">PMC6611653</a></div></div>
</div>
</div>
<!-- default theme -->

<style>
  /* import google fonts */
  @import url("https://fonts.googleapis.com/css?family=Open+Sans:400,600,700");
  @import url("https://fonts.googleapis.com/css?family=Source+Code+Pro");

  /* -------------------------------------------------- */
  /* global */
  /* -------------------------------------------------- */

  /* all elements */
  * {
    /* force sans-serif font unless specified otherwise */
    font-family: "Open Sans", "Helvetica", sans-serif;

    /* prevent text inflation on some mobile browsers */
    -webkit-text-size-adjust: none !important;
    -moz-text-size-adjust: none !important;
    -o-text-size-adjust: none !important;
    text-size-adjust: none !important;
  }

  @media only screen {
    /* "page" element */
    body {
      position: relative;
      box-sizing: border-box;
      font-size: 12pt;
      line-height: 1.5;
      max-width: 8.5in;
      margin: 20px auto;
      padding: 40px;
      border-radius: 5px;
      border: solid 1px #bdbdbd;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      background: #ffffff;
    }
  }

  /* when on screen < 8.5in wide */
  @media only screen and (max-width: 8.5in) {
    /* "page" element */
    body {
      padding: 20px;
      margin: 0;
      border-radius: 0;
      border: none;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05) inset;
      background: none;
    }
  }

  /* -------------------------------------------------- */
  /* headings */
  /* -------------------------------------------------- */

  /* all headings */
  h1,
  h2,
  h3,
  h4,
  h5,
  h6 {
    margin: 20px 0;
    padding: 0;
    font-weight: bold;
  }

  /* biggest heading */
  h1 {
    margin: 40px 0;
    text-align: center;
  }

  /* second biggest heading */
  h2 {
    margin-top: 30px;
    padding-bottom: 5px;
    border-bottom: solid 1px #bdbdbd;
  }

  /* heading font sizes */
  h1 {
    font-size: 2em;
  }
  h2 {
    font-size: 1.5em;
  }
  h3 {
    font-size: 1.35em;
  }
  h4 {
    font-size: 1.25em;
  }
  h5 {
    font-size: 1.15em;
  }
  h6 {
    font-size: 1em;
  }

  /* -------------------------------------------------- */
  /* manuscript header */
  /* -------------------------------------------------- */

  /* manuscript title */
  header > h1 {
    margin: 0;
  }

  /* manuscript title caption text (ie "automatically generated on") */
  header + p {
    text-align: center;
    margin-top: 10px;
  }

  /* -------------------------------------------------- */
  /* text elements */
  /* -------------------------------------------------- */

  /* links */
  a {
    color: #2196f3;
    overflow-wrap: break-word;
  }

  /* superscripts and subscripts */
  sub,
  sup {
    /* prevent from affecting line height */
    line-height: 0;
  }

  /* unordered and ordered lists*/
  ul,
  ol {
    padding-left: 20px;
  }

  /* class for styling text semibold */
  .semibold {
    font-weight: 600;
  }

  /* class for styling elements horizontally left aligned */
  .left {
    display: block;
    text-align: left;
    margin-left: auto;
    margin-right: 0;
    justify-content: left;
  }

  /* class for styling elements horizontally centered */
  .center {
    display: block;
    text-align: center;
    margin-left: auto;
    margin-right: auto;
    justify-content: center;
  }

  /* class for styling elements horizontally right aligned */
  .right {
    display: block;
    text-align: right;
    margin-left: 0;
    margin-right: auto;
    justify-content: right;
  }

  /* -------------------------------------------------- */
  /* section elements */
  /* -------------------------------------------------- */

  /* horizontal divider line */
  hr {
    border: none;
    height: 1px;
    background: #bdbdbd;
  }

  /* paragraphs, horizontal dividers, figures, tables, code */
  p,
  hr,
  figure,
  table,
  pre {
    /* treat all as "paragraphs", with consistent vertical margins */
    margin-top: 20px;
    margin-bottom: 20px;
  }

  /* -------------------------------------------------- */
  /* figures */
  /* -------------------------------------------------- */

  /* figure */
  figure {
    max-width: 100%;
    margin-left: auto;
    margin-right: auto;
  }

  /* figure caption */
  figcaption {
    padding: 0;
    padding-top: 10px;
  }

  /* figure image element */
  figure > img,
  figure > svg {
    max-width: 100%;
    display: block;
    margin-left: auto;
    margin-right: auto;
  }

  /* figure auto-number */
  img + figcaption > span:first-of-type,
  svg + figcaption > span:first-of-type {
    font-weight: bold;
    margin-right: 5px;
  }

  /* -------------------------------------------------- */
  /* tables */
  /* -------------------------------------------------- */

  /* table */
  table {
    border-collapse: collapse;
    border-spacing: 0;
    width: 100%;
    margin-left: auto;
    margin-right: auto;
  }

  /* table cells */
  th,
  td {
    border: solid 1px #bdbdbd;
    padding: 10px;
    /* squash table if too wide for page by forcing line breaks */
    overflow-wrap: break-word;
    word-break: break-word;
  }

  /* header row and even rows */
  th,
  tr:nth-child(2n) {
    background-color: #fafafa;
  }

  /* odd rows */
  tr:nth-child(2n + 1) {
    background-color: #ffffff;
  }

  /* table caption */
  caption {
    text-align: left;
    padding: 0;
    padding-bottom: 10px;
  }

  /* table auto-number */
  table > caption > span:first-of-type {
    font-weight: bold;
    margin-right: 5px;
  }

  /* -------------------------------------------------- */
  /* code */
  /* -------------------------------------------------- */

  /* multi-line code block */
  pre {
    padding: 10px;
    background-color: #eeeeee;
    color: #000000;
    border-radius: 5px;
    break-inside: avoid;
    text-align: left;
  }

  /* inline code, ie code within normal text */
  :not(pre) > code {
    padding: 0 4px;
    background-color: #eeeeee;
    color: #000000;
    border-radius: 5px;
  }

  /* code text */
  /* apply all children, to reach syntax highlighting sub-elements */
  code,
  code * {
    /* force monospace font */
    font-family: "Source Code Pro", "Courier New", monospace;
  }

  /* -------------------------------------------------- */
  /* quotes */
  /* -------------------------------------------------- */

  /* quoted text */
  blockquote {
    margin: 0;
    padding: 0;
    border-left: 4px solid #bdbdbd;
    padding-left: 16px;
    break-inside: avoid;
  }

  /* -------------------------------------------------- */
  /* banners */
  /* -------------------------------------------------- */

  /* info banners */
  .banner {
    box-sizing: border-box;
    display: block;
    position: relative;
    width: 100%;
    margin-top: 20px;
    margin-bottom: 20px;
    padding: 20px;
    text-align: center;
  }

  /* paragraph in banner */
  .banner > p {
    margin: 0;
  }

  /* -------------------------------------------------- */
  /* highlight colors */
  /* -------------------------------------------------- */

  .white {
    background: #ffffff;
  }
  .lightgrey {
    background: #eeeeee;
  }
  .grey {
    background: #757575;
  }
  .darkgrey {
    background: #424242;
  }
  .black {
    background: #000000;
  }
  .lightred {
    background: #ffcdd2;
  }
  .lightyellow {
    background: #ffecb3;
  }
  .lightgreen {
    background: #dcedc8;
  }
  .lightblue {
    background: #e3f2fd;
  }
  .lightpurple {
    background: #f3e5f5;
  }
  .red {
    background: #f44336;
  }
  .orange {
    background: #ff9800;
  }
  .yellow {
    background: #ffeb3b;
  }
  .green {
    background: #4caf50;
  }
  .blue {
    background: #2196f3;
  }
  .purple {
    background: #9c27b0;
  }
  .white,
  .lightgrey,
  .lightred,
  .lightyellow,
  .lightgreen,
  .lightblue,
  .lightpurple,
  .orange,
  .yellow,
  .white a,
  .lightgrey a,
  .lightred a,
  .lightyellow a,
  .lightgreen a,
  .lightblue a,
  .lightpurple a,
  .orange a,
  .yellow a {
    color: #000000;
  }
  .grey,
  .darkgrey,
  .black,
  .red,
  .green,
  .blue,
  .purple,
  .grey a,
  .darkgrey a,
  .black a,
  .red a,
  .green a,
  .blue a,
  .purple a {
    color: #ffffff;
  }

  /* -------------------------------------------------- */
  /* buttons */
  /* -------------------------------------------------- */

  /* class for styling links like buttons */
  .button {
    display: inline-flex;
    justify-content: center;
    align-items: center;
    margin: 5px;
    padding: 10px 20px;
    font-size: 0.75em;
    font-weight: 600;
    text-transform: uppercase;
    text-decoration: none;
    letter-spacing: 1px;
    background: none;
    color: #2196f3;
    border: solid 1px #bdbdbd;
    border-radius: 5px;
  }

  /* buttons when hovered */
  .button:hover:not([disabled]),
  .icon_button:hover:not([disabled]) {
    cursor: pointer;
    background: #f5f5f5;
  }

  /* buttons when disabled */
  .button[disabled],
  .icon_button[disabled] {
    opacity: 0.35;
    pointer-events: none;
  }

  /* class for styling buttons containg only single icon */
  .icon_button {
    display: inline-flex;
    justify-content: center;
    align-items: center;
    text-decoration: none;
    margin: 0;
    padding: 0;
    background: none;
    border-radius: 5px;
    border: none;
    width: 20px;
    height: 20px;
    min-width: 20px;
    min-height: 20px;
  }

  /* icon button inner svg image */
  .icon_button > svg {
    height: 16px;
  }

  /* -------------------------------------------------- */
  /* icons */
  /* -------------------------------------------------- */

  /* class for styling icons inline with text */
  .inline_icon {
    height: 1em;
    position: relative;
    top: 0.125em;
  }

  /* -------------------------------------------------- */
  /* references */
  /* -------------------------------------------------- */

  .csl-entry {
    margin-top: 15px;
    margin-bottom: 15px;
  }

  /* -------------------------------------------------- */
  /* print control */
  /* -------------------------------------------------- */

  @media print {
    @page {
      /* suggested printing margin */
      margin: 0.5in;
    }

    /* document and "page" elements */
    html,
    body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
    }

    /* "page" element */
    body {
      font-size: 11pt !important;
      line-height: 1.35;
    }

    /* all headings */
    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      margin: 15px 0;
    }

    /* figures and tables */
    figure,
    table {
      font-size: 0.85em;
    }

    /* table cells */
    th,
    td {
      padding: 5px;
    }

    /* shrink font awesome icons */
    i.fas,
    i.fab,
    i.far,
    i.fal {
      transform: scale(0.85);
    }

    /* decrease banner margins */
    .banner {
      margin-top: 15px;
      margin-bottom: 15px;
      padding: 15px;
    }

    /* class for centering an element vertically on its own page */
    .page_center {
      margin: auto;
      width: 100%;
      height: 100%;
      display: flex;
      align-items: center;
      vertical-align: middle;
      break-before: page;
      break-after: page;
    }

    /* always insert a page break before the element */
    .page_break_before {
      break-before: page;
    }

    /* always insert a page break after the element */
    .page_break_after {
      break-after: page;
    }

    /* avoid page break before the element */
    .page_break_before_avoid {
      break-before: avoid;
    }

    /* avoid page break after the element */
    .page_break_after_avoid {
      break-after: avoid;
    }

    /* avoid page break inside the element */
    .page_break_inside_avoid {
      break-inside: avoid;
    }
  }

  /* -------------------------------------------------- */
  /* override pandoc css quirks */
  /* -------------------------------------------------- */

  .sourceCode {
    /* prevent unsightly overflow in wide code blocks */
    overflow: auto !important;
  }

  div.sourceCode {
    /* prevent background fill on top-most code block  container */
    background: none !important;
  }

  .sourceCode * {
    /* force consistent line spacing */
    line-height: 1.5 !important;
  }

  div.sourceCode {
    /* style code block margins same as <pre> element */
    margin-top: 20px;
    margin-bottom: 20px;
  }

  /* -------------------------------------------------- */
  /* tablenos */
  /* -------------------------------------------------- */

  /* tablenos wrapper */
  .tablenos {
    width: 100%;
    margin: 20px 0;
  }

  .tablenos > table {
    /* move margins from table to table_wrapper to allow margin collapsing */
    margin: 0;
  }

  @media only screen {
    /* tablenos wrapper */
    .tablenos {
      /* show scrollbar on tables if necessary to prevent overflow */
      overflow-x: auto !important;
    }

    .tablenos th,
    .tablenos td {
      overflow-wrap: unset !important;
      word-break: unset !important;
    }

    /* table in wrapper */
    .tablenos table,
    .tablenos table * {
      /* don't break table words */
      overflow-wrap: normal !important;
    }
  }
</style>
<!-- 
    Plugin Core

    Functions needed for and shared across all first-party plugins.
-->

<script>
  // get element that is target of hash (from link element or url)
  function getHashTarget(link) {
    const hash = link ? link.hash : window.location.hash;
    const id = hash.slice(1);
    let target = document.querySelector(`[id="${id}"]`);
    if (!target) return;

    // if figure or table, modify target to get expected element
    if (id.indexOf("fig:") === 0) target = target.querySelector("figure");
    if (id.indexOf("tbl:") === 0) target = target.querySelector("table");

    return target;
  }

  // get position/dimensions of element or viewport
  function getRectInView(element) {
    let rect = {};
    rect.left = 0;
    rect.top = 0;
    rect.right = document.documentElement.clientWidth;
    rect.bottom = document.documentElement.clientHeight;
    let style = {};

    if (element instanceof HTMLElement) {
      rect = element.getBoundingClientRect();
      style = window.getComputedStyle(element);
    }

    const margin = {};
    margin.left = parseFloat(style.marginLeftWidth) || 0;
    margin.top = parseFloat(style.marginTopWidth) || 0;
    margin.right = parseFloat(style.marginRightWidth) || 0;
    margin.bottom = parseFloat(style.marginBottomWidth) || 0;

    const border = {};
    border.left = parseFloat(style.borderLeftWidth) || 0;
    border.top = parseFloat(style.borderTopWidth) || 0;
    border.right = parseFloat(style.borderRightWidth) || 0;
    border.bottom = parseFloat(style.borderBottomWidth) || 0;

    const newRect = {};
    newRect.left = rect.left + margin.left + border.left;
    newRect.top = rect.top + margin.top + border.top;
    newRect.right = rect.right + margin.right + border.right;
    newRect.bottom = rect.bottom + margin.bottom + border.bottom;
    newRect.width = newRect.right - newRect.left;
    newRect.height = newRect.bottom - newRect.top;

    return newRect;
  }

  // get position of element relative to page
  function getRectInPage(element) {
    const rect = getRectInView(element);
    const body = getRectInView(document.body);

    const newRect = {};
    newRect.left = rect.left - body.left;
    newRect.top = rect.top - body.top;
    newRect.right = rect.right - body.left;
    newRect.bottom = rect.bottom - body.top;
    newRect.width = rect.width;
    newRect.height = rect.height;

    return newRect;
  }

  // get closest element before specified element that matches query
  function firstBefore(element, query) {
    while (element && element !== document.body && !element.matches(query))
      element = element.previousElementSibling || element.parentNode;

    return element;
  }

  // check if element is part of collapsed heading
  function isCollapsed(element) {
    while (element && element !== document.body) {
      if (element.dataset.collapsed === "true") return true;
      element = element.parentNode;
    }
    return false;
  }

  // expand any collapsed parent containers of element if necessary
  function expandElement(element) {
    if (isCollapsed(element)) {
      // accordion plugin
      const heading = firstBefore(element, "h2");
      if (heading) heading.click();
      // details/summary HTML element
      const summary = firstBefore(element, "summary");
      if (summary) summary.click();
    }
  }

  // scroll to and focus element
  function goToElement(element, offset) {
    // expand accordion section if collapsed
    expandElement(element);
    const y =
      getRectInView(element).top -
      getRectInView(document.documentElement).top -
      (offset || 0);

    // trigger any function listening for "onscroll" event
    window.dispatchEvent(new Event("scroll"));
    window.scrollTo(0, y);
    document.activeElement.blur();
    element.focus();
  }

  // get list of elements after a start element up to element matching query
  function nextUntil(element, query, exclude) {
    const elements = [];
    while (((element = element.nextElementSibling), element)) {
      if (element.matches(query)) break;
      if (!element.matches(exclude)) elements.push(element);
    }
    return elements;
  }
</script>
<!--
  Accordion Plugin

  Allows sections of content under h2 headings to be collapsible.
-->

<script type="module">
  // whether to always start expanded ('false'), always start collapsed
  // ('true'), or start collapsed when screen small ('auto')
  const startCollapsed = "auto";

  // start script
  function start() {
    // run through each <h2> heading
    const headings = document.querySelectorAll("h2");
    for (const heading of headings) {
      addArrow(heading);

      // start expanded/collapsed based on option
      if (
        startCollapsed === "true" ||
        (startCollapsed === "auto" && isSmallScreen()) ||
        heading.dataset.collapsed === "true"
      )
        collapseHeading(heading);
      else expandElement(heading);
    }

    // attach hash change listener to window
    window.addEventListener("hashchange", onHashChange);
  }

  // when hash (eg manuscript.html#introduction) changes
  function onHashChange() {
    const target = getHashTarget();
    if (target) goToElement(target);
  }

  // add arrow to heading
  function addArrow(heading) {
    // add arrow button
    const arrow = document.createElement("button");
    arrow.innerHTML = document.querySelector(".icon_angle_down").innerHTML;
    arrow.classList.add("icon_button", "accordion_arrow");
    heading.insertBefore(arrow, heading.firstChild);

    // attach click listener to heading and button
    heading.addEventListener("click", onHeadingClick);
    arrow.addEventListener("click", onArrowClick);
  }

  // determine if on mobile-like device with small screen
  function isSmallScreen() {
    return Math.min(window.innerWidth, window.innerHeight) < 480;
  }

  // when <h2> heading is clicked
  function onHeadingClick(event) {
    // only collapse if <h2> itself is target of click (eg, user did
    // not click on anchor within <h2>)
    if (event.target === this) toggleCollapse(this);
  }

  // when arrow button is clicked
  function onArrowClick() {
    toggleCollapse(this.parentNode);
  }

  // collapse section if expanded, expand if collapsed
  function toggleCollapse(heading) {
    if (heading.dataset.collapsed === "false") collapseHeading(heading);
    else expandElement(heading);
  }

  // elements to exclude from collapse, such as table of contents panel,
  // hypothesis panel, etc
  const exclude = "#toc_panel, div.annotator-frame, #lightbox_overlay";

  // collapse section
  function collapseHeading(heading) {
    heading.setAttribute("data-collapsed", "true");
    const children = getChildren(heading);
    for (const child of children) child.setAttribute("data-collapsed", "true");
  }

  // expand section
  function expandElement(heading) {
    heading.setAttribute("data-collapsed", "false");
    const children = getChildren(heading);
    for (const child of children) child.setAttribute("data-collapsed", "false");
  }

  // get list of elements between this <h2> and next <h2> or <h1>
  // ("children" of the <h2> section)
  function getChildren(heading) {
    return nextUntil(heading, "h2, h1", exclude);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- angle down icon -->

<template class="icon_angle_down">
  <!-- modified from: https://fontawesome.com/icons/angle-down -->
  <svg width="16" height="16" viewBox="0 0 448 512">
    <path
      fill="currentColor"
      d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* accordion arrow button */
    .accordion_arrow {
      margin-right: 10px;
    }

    /* arrow icon when <h2> data-collapsed attribute true */
    h2[data-collapsed="true"] > .accordion_arrow > svg {
      transform: rotate(-90deg);
    }

    /* all elements (except <h2>'s) when data-collapsed attribute true */
    *:not(h2)[data-collapsed="true"] {
      display: none;
    }

    /* accordion arrow button when hovered and <h2>'s when hovered */
    .accordion_arrow:hover,
    h2[data-collapsed="true"]:hover,
    h2[data-collapsed="false"]:hover {
      cursor: pointer;
    }
  }

  /* always hide accordion arrow button on print */
  @media only print {
    .accordion_arrow {
      display: none;
    }
  }
</style>
<!--
  Anchors Plugin

  Adds an anchor next to each of a certain type of element that provides a
  human-readable url to that specific item/position in the document (e.g.
  "manuscript.html#abstract"). It also makes it such that scrolling out of view
  of a target removes its identifier from the url.
-->

<script type="module">
  // which types of elements to add anchors next to, in "document.querySelector"
  // format
  const typesQuery =
    'h1, h2, h3, div[id^="fig:"], div[id^="tbl:"], span[id^="eq:"]';

  // start script
  function start() {
    // add anchor to each element of specified types
    const elements = document.querySelectorAll(typesQuery);
    for (const element of elements) addAnchor(element);

    // attach scroll listener to window
    window.addEventListener("scroll", onScroll);
  }

  // when window is scrolled
  function onScroll() {
    // if url has hash and user has scrolled out of view of hash
    // target, remove hash from url
    const tolerance = 100;
    const target = getHashTarget();
    if (target) {
      if (
        target.getBoundingClientRect().top > window.innerHeight + tolerance ||
        target.getBoundingClientRect().bottom < 0 - tolerance
      )
        history.pushState(null, null, " ");
    }
  }

  // add anchor to element
  function addAnchor(element) {
    let addTo; // element to add anchor button to

    // if figure or table, modify withId and addTo to get expected
    // elements
    if (element.id.indexOf("fig:") === 0) {
      addTo = element.querySelector("figcaption");
    } else if (element.id.indexOf("tbl:") === 0) {
      addTo = element.querySelector("caption");
    } else if (element.id.indexOf("eq:") === 0) {
      addTo = element.querySelector(".eqnos-number");
    }

    addTo = addTo || element;
    const id = element.id || null;

    // do not add anchor if element doesn't have assigned id.
    // id is generated by pandoc and is assumed to be unique and
    // human-readable
    if (!id) return;

    // create anchor button
    const anchor = document.createElement("a");
    anchor.innerHTML = document.querySelector(".icon_link").innerHTML;
    anchor.title = "Link to this part of the document";
    anchor.classList.add("icon_button", "anchor");
    anchor.dataset.ignore = "true";
    anchor.href = "#" + id;
    addTo.appendChild(anchor);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- link icon -->

<template class="icon_link">
  <!-- modified from: https://fontawesome.com/icons/link -->
  <svg width="16" height="16" viewBox="0 0 512 512">
    <path
      fill="currentColor"
      d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* anchor button */
    .anchor {
      opacity: 0;
      margin-left: 5px;
    }

    /* anchor buttons within <h2>'s */
    h2 .anchor {
      margin-left: 10px;
    }

    /* anchor buttons when hovered/focused and anything containing an anchor button when hovered */
    *:hover > .anchor,
    .anchor:hover,
    .anchor:focus {
      opacity: 1;
    }

    /* anchor button when hovered */
    .anchor:hover {
      cursor: pointer;
    }
  }

  /* always show anchor button on devices with no mouse/hover ability */
  @media (hover: none) {
    .anchor {
      opacity: 1;
    }
  }

  /* always hide anchor button on print */
  @media only print {
    .anchor {
      display: none;
    }
  }
</style>
<!-- 
    Attributes Plugin

    Allows arbitrary HTML attributes to be attached to (almost) any element.
    Place an HTML comment inside or next to the desired element with the content:
    $attribute="value"
-->

<script type="module">
  // start script
  function start() {
    // get list of comments in document
    const comments = findComments();

    for (const comment of comments)
      if (comment.parentElement)
        addAttributes(comment.parentElement, comment.nodeValue.trim());
  }

  // add html attributes to specified element based on string of
  // html attributes and values
  function addAttributes(element, text) {
    // regex's for finding attribute/value pairs in the format of
    // attribute="value" or attribute='value
    const regex2 = /\$([a-zA-Z\-]+)?=\"(.+?)\"/;
    const regex1 = /\$([a-zA-Z\-]+)?=\'(.+?)\'/;

    // loop through attribute/value pairs
    let match;
    while ((match = text.match(regex2) || text.match(regex1))) {
      // get attribute and value from regex capture groups
      let attribute = match[1];
      let value = match[2];

      // remove from string
      text = text.substring(match.index + match[0].length);

      if (!attribute || !value) break;

      // set attribute of parent element
      try {
        element.setAttribute(attribute, value);
      } catch (error) {
        console.log(error);
      }

      // special case for colspan
      if (attribute === "colspan") removeTableCells(element, value);
    }
  }

  // get list of comment elements in document
  function findComments() {
    const comments = [];

    // iterate over comment nodes in document
    function acceptNode(node) {
      return NodeFilter.FILTER_ACCEPT;
    }
    const iterator = document.createNodeIterator(
      document.body,
      NodeFilter.SHOW_COMMENT,
      acceptNode
    );
    let node;
    while ((node = iterator.nextNode())) comments.push(node);

    return comments;
  }

  // remove certain number of cells after specified cell
  function removeTableCells(cell, number) {
    number = parseInt(number);
    if (!number) return;

    // remove elements
    for (; number > 1; number--) {
      if (cell.nextElementSibling) cell.nextElementSibling.remove();
    }
  }

  // start script on DOMContentLoaded instead of load to ensure this plugins
  // runs before other plugins
  window.addEventListener("DOMContentLoaded", start);
</script>
<!--
  Jump to First Plugin

  Adds a button next to each reference entry, figure, and table that jumps the
  page to the first occurrence of a link to that item in the manuscript.
-->

<script type="module">
  // whether to add buttons next to reference entries
  const references = "true";
  // whether to add buttons next to figures
  const figures = "true";
  // whether to add buttons next to tables
  const tables = "true";

  // start script
  function start() {
    if (references !== "false")
      makeButtons(`div[id^="ref-"]`, ".csl-left-margin", "reference");
    if (figures !== "false")
      makeButtons(`div[id^="fig:"]`, "figcaption", "figure");
    if (tables !== "false") makeButtons(`div[id^="tbl:"]`, "caption", "table");
  }

  // when jump button clicked
  function onButtonClick() {
    const first = getFirstOccurrence(this.dataset.id);
    if (!first) return;

    // update url hash so navigating "back" in history will return user to button
    window.location.hash = this.dataset.id;
    // scroll to link
    const timeout = function () {
      goToElement(first, window.innerHeight * 0.5);
    };
    window.setTimeout(timeout, 0);
  }

  // get first occurrence of link to item in document
  function getFirstOccurrence(id) {
    let query = "a";
    query += '[href="#' + id + '"]';
    // exclude buttons, anchor links, toc links, etc
    query += ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    return document.querySelector(query);
  }

  // add button next to each reference entry, figure, or table
  function makeButtons(query, containerQuery, subject) {
    const elements = document.querySelectorAll(query);
    for (const element of elements) {
      const id = element.id;
      const buttonContainer = element.querySelector(containerQuery);
      const first = getFirstOccurrence(id);

      // if can't find link to reference or place to put button, ignore
      if (!first || !buttonContainer) continue;

      // make jump button
      let button = document.createElement("button");
      button.classList.add("icon_button", "jump_arrow");
      button.title = `Jump to the first occurrence of this ${subject} in the document`;
      const icon = document.querySelector(".icon_angle_double_up");
      button.innerHTML = icon.innerHTML;
      button.dataset.id = id;
      button.dataset.ignore = "true";
      button.addEventListener("click", onButtonClick);
      buttonContainer.prepend(button);
    }
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- angle double up icon -->

<template class="icon_angle_double_up">
  <!-- modified from: https://fontawesome.com/icons/angle-double-up -->
  <svg width="16" height="16" viewBox="0 0 320 512">
    <path
      fill="currentColor"
      d="M177 255.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 351.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 425.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1zm-34-192L7 199.7c-9.4 9.4-9.4 24.6 0 33.9l22.6 22.6c9.4 9.4 24.6 9.4 33.9 0l96.4-96.4 96.4 96.4c9.4 9.4 24.6 9.4 33.9 0l22.6-22.6c9.4-9.4 9.4-24.6 0-33.9l-136-136c-9.2-9.4-24.4-9.4-33.8 0z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* jump button */
    .jump_arrow {
      position: relative;
      top: 0.125em;
      margin-right: 5px;
    }
  }

  /* always hide jump button on print */
  @media only print {
    .jump_arrow {
      display: none;
    }
  }
</style>
<!-- 
    Lightbox Plugin

    Makes it such that when a user clicks on an image, the image fills the
    screen and the user can pan/drag/zoom the image and navigate between other
    images in the document.
-->

<script type="module">
  // list of possible zoom/scale factors
  const zooms =
    "0.1, 0.25, 0.333333, 0.5, 0.666666, 0.75, 1, 1.25, 1.5, 1.75, 2, 2.5, 3, 3.5, 4, 5, 6, 7, 8";
  // whether to fit image to view ('fit'), display at 100% and shrink if
  // necessary ('shrink'), or always display at 100% ('100')
  const defaultZoom = "fit";
  // whether to zoom in/out toward center of view ('true') or mouse ('false')
  const centerZoom = "false";

  // start script
  function start() {
    // run through each <img> element
    const imgs = document.querySelectorAll("figure > img");
    let count = 1;
    for (const img of imgs) {
      img.classList.add("lightbox_document_img");
      img.dataset.number = count;
      img.dataset.total = imgs.length;
      img.addEventListener("click", openLightbox);
      count++;
    }

    // attach mouse and key listeners to window
    window.addEventListener("mousemove", onWindowMouseMove);
    window.addEventListener("keyup", onKeyUp);
  }

  // when mouse is moved anywhere in window
  function onWindowMouseMove(event) {
    window.mouseX = event.clientX;
    window.mouseY = event.clientY;
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    switch (event.key) {
      // trigger click of prev button
      case "ArrowLeft":
        const prevButton = document.getElementById("lightbox_prev_button");
        if (prevButton) prevButton.click();
        break;
      // trigger click of next button
      case "ArrowRight":
        const nextButton = document.getElementById("lightbox_next_button");
        if (nextButton) nextButton.click();
        break;
      // close on esc
      case "Escape":
        closeLightbox();
        break;
    }
  }

  // open lightbox
  function openLightbox() {
    const lightbox = makeLightbox(this);
    if (!lightbox) return;

    blurBody(lightbox);
    document.body.appendChild(lightbox);
  }

  // make lightbox
  function makeLightbox(img) {
    // delete lightbox if it exists, start fresh
    closeLightbox();

    // create screen overlay containing lightbox
    const overlay = document.createElement("div");
    overlay.id = "lightbox_overlay";

    // create image info boxes
    const numberInfo = document.createElement("div");
    const zoomInfo = document.createElement("div");
    numberInfo.id = "lightbox_number_info";
    zoomInfo.id = "lightbox_zoom_info";

    // create container for image
    const imageContainer = document.createElement("div");
    imageContainer.id = "lightbox_image_container";
    const lightboxImg = makeLightboxImg(
      img,
      imageContainer,
      numberInfo,
      zoomInfo
    );
    imageContainer.appendChild(lightboxImg);

    // create bottom container for caption and navigation buttons
    const bottomContainer = document.createElement("div");
    bottomContainer.id = "lightbox_bottom_container";
    const caption = makeCaption(img);
    const prevButton = makePrevButton(img);
    const nextButton = makeNextButton(img);
    bottomContainer.appendChild(prevButton);
    bottomContainer.appendChild(caption);
    bottomContainer.appendChild(nextButton);

    // attach top middle and bottom to overlay
    overlay.appendChild(numberInfo);
    overlay.appendChild(zoomInfo);
    overlay.appendChild(imageContainer);
    overlay.appendChild(bottomContainer);

    return overlay;
  }

  // make <img> object that is intuitively draggable and zoomable
  function makeLightboxImg(sourceImg, container, numberInfoBox, zoomInfoBox) {
    // create copy of source <img>
    const img = sourceImg.cloneNode(true);
    img.classList.remove("lightbox_document_img");
    img.removeAttribute("id");
    img.removeAttribute("width");
    img.removeAttribute("height");
    img.style.position = "unset";
    img.style.margin = "0";
    img.style.padding = "0";
    img.style.width = "";
    img.style.height = "";
    img.style.minWidth = "";
    img.style.minHeight = "";
    img.style.maxWidth = "";
    img.style.maxHeight = "";
    img.id = "lightbox_img";

    // build sorted list of zoomSteps
    const zoomSteps = zooms.split(/[^0-9.]/).map((step) => parseFloat(step));
    zoomSteps.sort((a, b) => a - b);

    // <img> object property variables
    let zoom = 1;
    let translateX = 0;
    let translateY = 0;
    let clickMouseX = undefined;
    let clickMouseY = undefined;
    let clickTranslateX = undefined;
    let clickTranslateY = undefined;

    updateNumberInfo();

    // update image numbers displayed in info box
    function updateNumberInfo() {
      numberInfoBox.innerHTML =
        sourceImg.dataset.number + " of " + sourceImg.dataset.total;
    }

    // update zoom displayed in info box
    function updateZoomInfo() {
      let zoomInfo = zoom * 100;
      if (!Number.isInteger(zoomInfo)) zoomInfo = zoomInfo.toFixed(2);
      zoomInfoBox.innerHTML = zoomInfo + "%";
    }

    // move to closest zoom step above current zoom
    const zoomIn = function () {
      for (const zoomStep of zoomSteps) {
        if (zoomStep > zoom) {
          zoom = zoomStep;
          break;
        }
      }
      updateTransform();
    };

    // move to closest zoom step above current zoom
    const zoomOut = function () {
      zoomSteps.reverse();
      for (const zoomStep of zoomSteps) {
        if (zoomStep < zoom) {
          zoom = zoomStep;
          break;
        }
      }
      zoomSteps.reverse();

      updateTransform();
    };

    // update display of <img> based on scale/translate properties
    const updateTransform = function () {
      // set transform
      img.style.transform =
        "translate(" +
        (translateX || 0) +
        "px," +
        (translateY || 0) +
        "px) scale(" +
        (zoom || 1) +
        ")";

      // get new width/height after scale
      const rect = img.getBoundingClientRect();
      // limit translate
      translateX = Math.max(translateX, -rect.width / 2);
      translateX = Math.min(translateX, rect.width / 2);
      translateY = Math.max(translateY, -rect.height / 2);
      translateY = Math.min(translateY, rect.height / 2);

      // set transform
      img.style.transform =
        "translate(" +
        (translateX || 0) +
        "px," +
        (translateY || 0) +
        "px) scale(" +
        (zoom || 1) +
        ")";

      updateZoomInfo();
    };

    // fit <img> to container
    const fit = function () {
      // no x/y offset, 100% zoom by default
      translateX = 0;
      translateY = 0;
      zoom = 1;

      // widths of <img> and container
      const imgWidth = img.naturalWidth;
      const imgHeight = img.naturalHeight;
      const containerWidth = parseFloat(
        window.getComputedStyle(container).width
      );
      const containerHeight = parseFloat(
        window.getComputedStyle(container).height
      );

      // how much zooming is needed to fit <img> to container
      const xRatio = imgWidth / containerWidth;
      const yRatio = imgHeight / containerHeight;
      const maxRatio = Math.max(xRatio, yRatio);
      const newZoom = 1 / maxRatio;

      // fit <img> to container according to option
      if (defaultZoom === "shrink") {
        if (maxRatio > 1) zoom = newZoom;
      } else if (defaultZoom === "fit") zoom = newZoom;

      updateTransform();
    };

    // when mouse wheel is rolled anywhere in container
    const onContainerWheel = function (event) {
      if (!event) return;

      // let ctrl + mouse wheel to zoom behave as normal
      if (event.ctrlKey) return;

      // prevent normal scroll behavior
      event.preventDefault();
      event.stopPropagation();

      // point around which to scale img
      const viewRect = container.getBoundingClientRect();
      const viewX = (viewRect.left + viewRect.right) / 2;
      const viewY = (viewRect.top + viewRect.bottom) / 2;
      const originX = centerZoom === "true" ? viewX : mouseX;
      const originY = centerZoom === "true" ? viewY : mouseY;

      // get point on image under origin
      const oldRect = img.getBoundingClientRect();
      const oldPercentX = (originX - oldRect.left) / oldRect.width;
      const oldPercentY = (originY - oldRect.top) / oldRect.height;

      // increment/decrement zoom
      if (event.deltaY < 0) zoomIn();
      if (event.deltaY > 0) zoomOut();

      // get offset between previous image point and origin
      const newRect = img.getBoundingClientRect();
      const offsetX = originX - (newRect.left + newRect.width * oldPercentX);
      const offsetY = originY - (newRect.top + newRect.height * oldPercentY);

      // translate image to keep image point under origin
      translateX += offsetX;
      translateY += offsetY;

      // perform translate
      updateTransform();
    };

    // when container is clicked
    function onContainerClick(event) {
      // if container itself is target of click, and not other
      // element above it
      if (event.target === this) closeLightbox();
    }

    // when mouse button is pressed on image
    const onImageMouseDown = function (event) {
      // store original mouse position relative to image
      clickMouseX = window.mouseX;
      clickMouseY = window.mouseY;
      clickTranslateX = translateX;
      clickTranslateY = translateY;
      event.stopPropagation();
      event.preventDefault();
    };

    // when mouse button is released anywhere in window
    const onWindowMouseUp = function (event) {
      // reset original mouse position
      clickMouseX = undefined;
      clickMouseY = undefined;
      clickTranslateX = undefined;
      clickTranslateY = undefined;

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("mouseup", onWindowMouseUp);
    };

    // when mouse is moved anywhere in window
    const onWindowMouseMove = function (event) {
      if (
        clickMouseX === undefined ||
        clickMouseY === undefined ||
        clickTranslateX === undefined ||
        clickTranslateY === undefined
      )
        return;

      // offset image based on original and current mouse position
      translateX = clickTranslateX + window.mouseX - clickMouseX;
      translateY = clickTranslateY + window.mouseY - clickMouseY;
      updateTransform();
      event.preventDefault();

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("mousemove", onWindowMouseMove);
    };

    // when window is resized
    const onWindowResize = function (event) {
      fit();

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("resize", onWindowResize);
    };

    // attach the necessary event listeners
    img.addEventListener("dblclick", fit);
    img.addEventListener("mousedown", onImageMouseDown);
    container.addEventListener("wheel", onContainerWheel);
    container.addEventListener("mousedown", onContainerClick);
    container.addEventListener("touchstart", onContainerClick);
    window.addEventListener("mouseup", onWindowMouseUp);
    window.addEventListener("mousemove", onWindowMouseMove);
    window.addEventListener("resize", onWindowResize);

    // run fit() after lightbox atttached to document and <img> Loaded
    // so needed container and img dimensions available
    img.addEventListener("load", fit);

    return img;
  }

  // make caption
  function makeCaption(img) {
    const caption = document.createElement("div");
    caption.id = "lightbox_caption";
    const captionSource = img.nextElementSibling;
    if (captionSource.tagName.toLowerCase() === "figcaption") {
      const captionCopy = makeCopy(captionSource);
      caption.innerHTML = captionCopy.innerHTML;
    }

    caption.addEventListener("touchstart", function (event) {
      event.stopPropagation();
    });

    return caption;
  }

  // make carbon copy of html dom element
  function makeCopy(source) {
    const sourceCopy = source.cloneNode(true);

    // delete elements marked with ignore (eg anchor and jump buttons)
    const deleteFromCopy = sourceCopy.querySelectorAll('[data-ignore="true"]');
    for (const element of deleteFromCopy) element.remove();

    // delete certain element attributes
    const attributes = [
      "id",
      "data-collapsed",
      "data-selected",
      "data-highlighted",
      "data-glow",
    ];
    for (const attribute of attributes) {
      sourceCopy.removeAttribute(attribute);
      const elements = sourceCopy.querySelectorAll("[" + attribute + "]");
      for (const element of elements) element.removeAttribute(attribute);
    }

    return sourceCopy;
  }

  // make button to jump to previous image in document
  function makePrevButton(img) {
    const prevButton = document.createElement("button");
    prevButton.id = "lightbox_prev_button";
    prevButton.title = "Jump to the previous image in the document [←]";
    prevButton.classList.add("icon_button", "lightbox_button");
    prevButton.innerHTML = document.querySelector(".icon_caret_left").innerHTML;

    // attach click listeners to button
    prevButton.addEventListener("click", function () {
      getPrevImg(img).click();
    });

    return prevButton;
  }

  // make button to jump to next image in document
  function makeNextButton(img) {
    const nextButton = document.createElement("button");
    nextButton.id = "lightbox_next_button";
    nextButton.title = "Jump to the next image in the document [→]";
    nextButton.classList.add("icon_button", "lightbox_button");
    nextButton.innerHTML = document.querySelector(
      ".icon_caret_right"
    ).innerHTML;

    // attach click listeners to button
    nextButton.addEventListener("click", function () {
      getNextImg(img).click();
    });

    return nextButton;
  }

  // get previous image in document
  function getPrevImg(img) {
    const imgs = document.querySelectorAll(".lightbox_document_img");

    // find index of provided img
    let index;
    for (index = 0; index < imgs.length; index++) {
      if (imgs[index] === img) break;
    }

    // wrap index to other side if < 1
    if (index - 1 >= 0) index--;
    else index = imgs.length - 1;
    return imgs[index];
  }

  // get next image in document
  function getNextImg(img) {
    const imgs = document.querySelectorAll(".lightbox_document_img");

    // find index of provided img
    let index;
    for (index = 0; index < imgs.length; index++) {
      if (imgs[index] === img) break;
    }

    // wrap index to other side if > total
    if (index + 1 <= imgs.length - 1) index++;
    else index = 0;
    return imgs[index];
  }

  // close lightbox
  function closeLightbox() {
    focusBody();

    const lightbox = document.getElementById("lightbox_overlay");
    if (lightbox) lightbox.remove();
  }

  // make all elements behind lightbox non-focusable
  function blurBody(overlay) {
    const all = document.querySelectorAll("*");
    for (const element of all) element.tabIndex = -1;
    document.body.classList.add("body_no_scroll");
  }

  // make all elements focusable again
  function focusBody() {
    const all = document.querySelectorAll("*");
    for (const element of all) element.removeAttribute("tabIndex");
    document.body.classList.remove("body_no_scroll");
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
  <!-- modified from: https://fontawesome.com/icons/caret-left -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
    ></path>
  </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
  <!-- modified from: https://fontawesome.com/icons/caret-right -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* regular <img> in document when hovered */
    img.lightbox_document_img:hover {
      cursor: pointer;
    }

    .body_no_scroll {
      overflow: hidden !important;
    }

    /* screen overlay */
    #lightbox_overlay {
      display: flex;
      flex-direction: column;
      position: fixed;
      left: 0;
      top: 0;
      right: 0;
      bottom: 0;
      background: rgba(0, 0, 0, 0.75);
      z-index: 3;
    }

    /* middle area containing lightbox image */
    #lightbox_image_container {
      flex-grow: 1;
      display: flex;
      justify-content: center;
      align-items: center;
      overflow: hidden;
      position: relative;
      padding: 20px;
    }

    /* bottom area containing caption */
    #lightbox_bottom_container {
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100px;
      min-height: 100px;
      max-height: 100px;
      background: rgba(0, 0, 0, 0.5);
    }

    /* image number info text box */
    #lightbox_number_info {
      position: absolute;
      color: #ffffff;
      font-weight: 600;
      left: 2px;
      top: 0;
      z-index: 4;
    }

    /* zoom info text box */
    #lightbox_zoom_info {
      position: absolute;
      color: #ffffff;
      font-weight: 600;
      right: 2px;
      top: 0;
      z-index: 4;
    }

    /* copy of image caption */
    #lightbox_caption {
      box-sizing: border-box;
      display: inline-block;
      width: 100%;
      max-height: 100%;
      padding: 10px 0;
      text-align: center;
      overflow-y: auto;
      color: #ffffff;
    }

    /* navigation previous/next button */
    .lightbox_button {
      width: 100px;
      height: 100%;
      min-width: 100px;
      min-height: 100%;
      color: #ffffff;
    }

    /* navigation previous/next button when hovered */
    .lightbox_button:hover {
      background: none !important;
    }

    /* navigation button icon */
    .lightbox_button > svg {
      height: 25px;
    }

    /* figure auto-number */
    #lightbox_caption > span:first-of-type {
      font-weight: bold;
      margin-right: 5px;
    }

    /* lightbox image when hovered */
    #lightbox_img:hover {
      cursor: grab;
    }

    /* lightbox image when grabbed */
    #lightbox_img:active {
      cursor: grabbing;
    }
  }

  /* when on screen < 480px wide */
  @media only screen and (max-width: 480px) {
    /* make navigation buttons skinnier on small screens to make more room for caption text */
    .lightbox_button {
      width: 50px;
      min-width: 50px;
    }
  }

  /* always hide lightbox on print */
  @media only print {
    #lightbox_overlay {
      display: none;
    }
  }
</style>
<!-- 
  Link Highlight Plugin

  Makes it such that when a user hovers or focuses a link, other links that have
  the same target will be highlighted. It also makes it such that when clicking
  a link, the target of the link (eg reference, figure, table) is briefly
  highlighted.
-->

<script type="module">
  // whether to also highlight links that go to external urls
  const externalLinks = "false";
  // whether user must click off to unhighlight instead of just
  // un-hovering
  const clickUnhighlight = "false";
  // whether to also highlight links that are unique
  const highlightUnique = "true";

  // start script
  function start() {
    const links = getLinks();
    for (const link of links) {
      // attach mouse and focus listeners to link
      link.addEventListener("mouseenter", onLinkFocus);
      link.addEventListener("focus", onLinkFocus);
      link.addEventListener("mouseleave", onLinkUnhover);
    }

    // attach click and hash change listeners to window
    window.addEventListener("click", onClick);
    window.addEventListener("touchstart", onClick);
    window.addEventListener("hashchange", onHashChange);

    // run hash change on window load in case user has navigated
    // directly to hash
    onHashChange();
  }

  // when link is focused (tabbed to) or hovered
  function onLinkFocus() {
    highlight(this);
  }

  // when link is unhovered
  function onLinkUnhover() {
    if (clickUnhighlight !== "true") unhighlightAll();
  }

  // when the mouse is clicked anywhere in window
  function onClick(event) {
    unhighlightAll();
  }

  // when hash (eg manuscript.html#introduction) changes
  function onHashChange() {
    const target = getHashTarget();
    if (target) glowElement(target);
  }

  // start glow sequence on an element
  function glowElement(element) {
    const startGlow = function () {
      onGlowEnd();
      element.dataset.glow = "true";
      element.addEventListener("animationend", onGlowEnd);
    };
    const onGlowEnd = function () {
      element.removeAttribute("data-glow");
      element.removeEventListener("animationend", onGlowEnd);
    };
    startGlow();
  }

  // highlight link and all others with same target
  function highlight(link) {
    // force unhighlight all to start fresh
    unhighlightAll();

    // get links with same target
    if (!link) return;
    const sameLinks = getSameLinks(link);

    // if link unique and option is off, exit and don't highlight
    if (sameLinks.length <= 1 && highlightUnique !== "true") return;

    // highlight all same links, and "select" (special highlight) this
    // one
    for (const sameLink of sameLinks) {
      if (sameLink === link) sameLink.setAttribute("data-selected", "true");
      else sameLink.setAttribute("data-highlighted", "true");
    }
  }

  // unhighlight all links
  function unhighlightAll() {
    const links = getLinks();
    for (const link of links) {
      link.setAttribute("data-selected", "false");
      link.setAttribute("data-highlighted", "false");
    }
  }

  // get links with same target
  function getSameLinks(link) {
    const results = [];
    const links = getLinks();
    for (const otherLink of links) {
      if (otherLink.getAttribute("href") === link.getAttribute("href"))
        results.push(otherLink);
    }
    return results;
  }

  // get all links of types we wish to handle
  function getLinks() {
    let query = "a";
    if (externalLinks !== "true") query += '[href^="#"]';
    // exclude buttons, anchor links, toc links, etc
    query += ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    return document.querySelectorAll(query);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<style>
  @media only screen {
    /* anything with data-highlighted attribute true */
    [data-highlighted="true"] {
      background: #ffeb3b;
    }

    /* anything with data-selected attribute true */
    [data-selected="true"] {
      background: #ff8a65 !important;
    }

    /* animation definition for glow */
    @keyframes highlight_glow {
      0% {
        background: none;
      }
      10% {
        background: #bbdefb;
      }
      100% {
        background: none;
      }
    }

    /* anything with data-glow attribute true */
    [data-glow="true"] {
      animation: highlight_glow 2s;
    }
  }
</style>
<!--
  Table of Contents Plugin

  Provides a "table of contents" (toc) panel on the side of the document that
  allows the user to conveniently navigate between sections of the document.
-->

<script type="module">
  // which types of elements to add links for, in "document.querySelector" format
  const typesQuery = "h1, h2, h3";
  // whether toc starts open. use 'true' or 'false', or 'auto' to
  // use 'true' behavior when screen wide enough and 'false' when not
  const startOpen = "false";
  // whether toc closes when clicking on toc link. use 'true' or
  // 'false', or 'auto' to use 'false' behavior when screen wide
  // enough and 'true' when not
  const clickClose = "auto";
  // if list item is more than this many characters, text will be
  // truncated
  const charLimit = "50";
  // whether or not to show bullets next to each toc item
  const bullets = "false";

  // start script
  function start() {
    // make toc panel and populate with entries (links to document
    // sections)
    const panel = makePanel();
    if (!panel) return;
    makeEntries(panel);
    // attach panel to document after making entries, so 'toc' heading
    // in panel isn't included in toc
    document.body.insertBefore(panel, document.body.firstChild);

    // initial panel state
    if (startOpen === "true" || (startOpen === "auto" && !isSmallScreen()))
      openPanel();
    else closePanel();

    // attach click, scroll, and hash change listeners to window
    window.addEventListener("click", onClick);
    window.addEventListener("scroll", onScroll);
    window.addEventListener("hashchange", onScroll);
    window.addEventListener("keyup", onKeyUp);
    onScroll();

    // add class to push document body down out of way of toc button
    document.body.classList.add("toc_body_nudge");
  }

  // determine if screen wide enough to fit toc panel
  function isSmallScreen() {
    // in default theme:
    // 816px = 8.5in = width of "page" (<body>) element
    // 260px = min width of toc panel (*2 for both sides of <body>)
    return window.innerWidth < 816 + 260 * 2;
  }

  // when mouse is clicked anywhere in window
  function onClick() {
    if (isSmallScreen()) closePanel();
  }

  // when window is scrolled or hash changed
  function onScroll() {
    highlightViewed();
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    // close on esc
    if (event.key === "Escape") closePanel();
  }

  // find entry of currently viewed document section in toc and highlight
  function highlightViewed() {
    const firstId = getFirstInView(typesQuery);

    // get toc entries (links), unhighlight all, then highlight viewed
    const list = document.getElementById("toc_list");
    if (!firstId || !list) return;
    const links = list.querySelectorAll("a");
    for (const link of links) link.dataset.viewing = "false";
    const link = list.querySelector('a[href="#' + firstId + '"]');
    if (!link) return;
    link.dataset.viewing = "true";
  }

  // get first or previous toc listed element in top half of view
  function getFirstInView(query) {
    // get all elements matching query and with id
    const elements = document.querySelectorAll(query);
    const elementsWithIds = [];
    for (const element of elements) {
      if (element.id) elementsWithIds.push(element);
    }

    // get first or previous element in top half of view
    for (let i = 0; i < elementsWithIds.length; i++) {
      const element = elementsWithIds[i];
      const prevElement = elementsWithIds[Math.max(0, i - 1)];
      if (element.getBoundingClientRect().top >= 0) {
        if (element.getBoundingClientRect().top < window.innerHeight / 2)
          return element.id;
        else return prevElement.id;
      }
    }
  }

  // make panel
  function makePanel() {
    // create panel
    const panel = document.createElement("div");
    panel.id = "toc_panel";
    if (bullets === "true") panel.dataset.bullets = "true";

    // create header
    const header = document.createElement("div");
    header.id = "toc_header";

    // create toc button
    const button = document.createElement("button");
    button.id = "toc_button";
    button.innerHTML = document.querySelector(".icon_th_list").innerHTML;
    button.title = "Table of Contents";
    button.classList.add("icon_button");

    // create header text
    const text = document.createElement("h4");
    text.innerHTML = "Table of Contents";

    // create container for toc list
    const list = document.createElement("div");
    list.id = "toc_list";

    // attach click listeners
    panel.addEventListener("click", onPanelClick);
    header.addEventListener("click", onHeaderClick);
    button.addEventListener("click", onButtonClick);

    // attach elements
    header.appendChild(button);
    header.appendChild(text);
    panel.appendChild(header);
    panel.appendChild(list);

    return panel;
  }

  // create toc entries (links) to each element of the specified types
  function makeEntries(panel) {
    const elements = document.querySelectorAll(typesQuery);
    for (const element of elements) {
      // do not add link if element doesn't have assigned id
      if (!element.id) continue;

      // create link/list item
      const link = document.createElement("a");
      link.classList.add("toc_link");
      switch (element.tagName.toLowerCase()) {
        case "h1":
          link.dataset.level = "1";
          break;
        case "h2":
          link.dataset.level = "2";
          break;
        case "h3":
          link.dataset.level = "3";
          break;
        case "h4":
          link.dataset.level = "4";
          break;
      }
      link.title = element.innerText;
      let text = element.innerText;
      if (text.length > charLimit) text = text.slice(0, charLimit) + "...";
      link.innerHTML = text;
      link.href = "#" + element.id;
      link.addEventListener("click", onLinkClick);

      // attach link
      panel.querySelector("#toc_list").appendChild(link);
    }
  }

  // when panel is clicked
  function onPanelClick(event) {
    // stop click from propagating to window/document and closing panel
    event.stopPropagation();
  }

  // when header itself is clicked
  function onHeaderClick(event) {
    togglePanel();
  }

  // when button is clicked
  function onButtonClick(event) {
    togglePanel();
    // stop header underneath button from also being clicked
    event.stopPropagation();
  }

  // when link is clicked
  function onLinkClick(event) {
    if (clickClose === "true" || (clickClose === "auto" && isSmallScreen()))
      closePanel();
    else openPanel();
  }

  // open panel if closed, close if opened
  function togglePanel() {
    const panel = document.getElementById("toc_panel");
    if (!panel) return;

    if (panel.dataset.open === "true") closePanel();
    else openPanel();
  }

  // open panel
  function openPanel() {
    const panel = document.getElementById("toc_panel");
    if (panel) panel.dataset.open = "true";
  }

  // close panel
  function closePanel() {
    const panel = document.getElementById("toc_panel");
    if (panel) panel.dataset.open = "false";
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- th list icon -->

<template class="icon_th_list">
  <!-- modified from: https://fontawesome.com/icons/th-list -->
  <svg width="16" height="16" viewBox="0 0 512 512" tabindex="-1">
    <path
      fill="currentColor"
      d="M96 96c0 26.51-21.49 48-48 48S0 122.51 0 96s21.49-48 48-48 48 21.49 48 48zM48 208c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm0 160c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm96-236h352c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"
      tabindex="-1"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* toc panel */
    #toc_panel {
      box-sizing: border-box;
      position: fixed;
      top: 0;
      left: 0;
      background: #ffffff;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      z-index: 2;
    }

    /* toc panel when closed */
    #toc_panel[data-open="false"] {
      min-width: 60px;
      width: 60px;
      height: 60px;
      border-right: solid 1px #bdbdbd;
      border-bottom: solid 1px #bdbdbd;
    }

    /* toc panel when open */
    #toc_panel[data-open="true"] {
      min-width: 260px;
      max-width: 480px;
      /* keep panel edge consistent distance away from "page" edge */
      width: calc(((100vw - 8.5in) / 2) - 30px - 40px);
      bottom: 0;
      border-right: solid 1px #bdbdbd;
    }

    /* toc panel header */
    #toc_header {
      box-sizing: border-box;
      display: flex;
      flex-direction: row;
      align-items: center;
      height: 60px;
      margin: 0;
      padding: 20px;
    }

    /* toc panel header when hovered */
    #toc_header:hover {
      cursor: pointer;
    }

    /* toc panel header when panel open */
    #toc_panel[data-open="true"] > #toc_header {
      border-bottom: solid 1px #bdbdbd;
    }

    /* toc open/close header button */
    #toc_button {
      margin-right: 20px;
    }

    /* hide toc list and header text when closed */
    #toc_panel[data-open="false"] > #toc_header > *:not(#toc_button),
    #toc_panel[data-open="false"] > #toc_list {
      display: none;
    }

    /* toc list of entries */
    #toc_list {
      box-sizing: border-box;
      width: 100%;
      padding: 20px;
      position: absolute;
      top: calc(60px + 1px);
      bottom: 0;
      overflow: auto;
    }

    /* toc entry, link to section in document */
    .toc_link {
      display: block;
      padding: 5px;
      position: relative;
      font-weight: 600;
      text-decoration: none;
    }

    /* toc entry when hovered or when "viewed" */
    .toc_link:hover,
    .toc_link[data-viewing="true"] {
      background: #f5f5f5;
    }

    /* toc entry, level 1 indentation */
    .toc_link[data-level="1"] {
      margin-left: 0;
    }

    /* toc entry, level 2 indentation */
    .toc_link[data-level="2"] {
      margin-left: 20px;
    }

    /* toc entry, level 3 indentation */
    .toc_link[data-level="3"] {
      margin-left: 40px;
    }

    /* toc entry, level 4 indentation */
    .toc_link[data-level="4"] {
      margin-left: 60px;
    }

    /* toc entry bullets */
    #toc_panel[data-bullets="true"] .toc_link[data-level]:before {
      position: absolute;
      left: -15px;
      top: -1px;
      font-size: 1.5em;
    }

    /* toc entry, level 2 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="2"]:before {
      content: "\2022";
    }

    /* toc entry, level 3 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="3"]:before {
      content: "\25AB";
    }

    /* toc entry, level 4 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="4"]:before {
      content: "-";
    }
  }

  /* when on screen < 8.5in wide */
  @media only screen and (max-width: 8.5in) {
    /* push <body> ("page") element down to make room for toc icon */
    .toc_body_nudge {
      padding-top: 60px;
    }

    /* toc icon when panel closed and not hovered */
    #toc_panel[data-open="false"]:not(:hover) {
      background: rgba(255, 255, 255, 0.75);
    }
  }

  /* always hide toc panel on print */
  @media only print {
    #toc_panel {
      display: none;
    }
  }
</style>
<!-- 
  Tooltips Plugin

  Makes it such that when the user hovers or focuses a link to a citation or
  figure, a tooltip appears with a preview of the reference content, along with
  arrows to navigate between instances of the same reference in the document.
-->

<script type="module">
  // whether user must click off to close tooltip instead of just un-hovering
  const clickClose = "false";
  // delay (in ms) between opening and closing tooltip
  const delay = "100";

  // start script
  function start() {
    const links = getLinks();
    for (const link of links) {
      // attach hover and focus listeners to link
      link.addEventListener("mouseover", onLinkHover);
      link.addEventListener("mouseleave", onLinkUnhover);
      link.addEventListener("focus", onLinkFocus);
      link.addEventListener("touchend", onLinkTouch);
    }

    // attach mouse, key, and resize listeners to window
    window.addEventListener("mousedown", onClick);
    window.addEventListener("touchstart", onClick);
    window.addEventListener("keyup", onKeyUp);
    window.addEventListener("resize", onResize);
  }

  // when link is hovered
  function onLinkHover() {
    // function to open tooltip
    const delayOpenTooltip = function () {
      openTooltip(this);
    }.bind(this);

    // run open function after delay
    this.openTooltipTimer = window.setTimeout(delayOpenTooltip, delay);
  }

  // when mouse leaves link
  function onLinkUnhover() {
    // cancel opening tooltip
    window.clearTimeout(this.openTooltipTimer);

    // don't close on unhover if option specifies
    if (clickClose === "true") return;

    // function to close tooltip
    const delayCloseTooltip = function () {
      // if tooltip open and if mouse isn't over tooltip, close
      const tooltip = document.getElementById("tooltip");
      if (tooltip && !tooltip.matches(":hover")) closeTooltip();
    };

    // run close function after delay
    this.closeTooltipTimer = window.setTimeout(delayCloseTooltip, delay);
  }

  // when link is focused (tabbed to)
  function onLinkFocus(event) {
    openTooltip(this);
  }

  // when link is touched on touch screen
  function onLinkTouch(event) {
    // attempt to force hover state on first tap always, and trigger
    // regular link click (and navigation) on second tap
    if (event.target === document.activeElement) event.target.click();
    else {
      document.activeElement.blur();
      event.target.focus();
    }
    if (event.cancelable) event.preventDefault();
    event.stopPropagation();
    return false;
  }

  // when mouse is clicked anywhere in window
  function onClick(event) {
    closeTooltip();
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    switch (event.key) {
      // trigger click of prev button
      case "ArrowLeft":
        const prevButton = document.getElementById("tooltip_prev_button");
        if (prevButton) prevButton.click();
        break;
      // trigger click of next button
      case "ArrowRight":
        const nextButton = document.getElementById("tooltip_next_button");
        if (nextButton) nextButton.click();
        break;
      // close on esc
      case "Escape":
        closeTooltip();
        break;
    }
  }

  // when window is resized or zoomed
  function onResize() {
    closeTooltip();
  }

  // get all links of types we wish to handle
  function getLinks() {
    const queries = [];
    // exclude buttons, anchor links, toc links, etc
    const exclude =
      ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    queries.push('a[href^="#ref-"]' + exclude); // citation links
    queries.push('a[href^="#fig:"]' + exclude); // figure links
    const query = queries.join(", ");
    return document.querySelectorAll(query);
  }

  // get links with same target, get index of link in set, get total
  // same links
  function getSameLinks(link) {
    const sameLinks = [];
    const links = getLinks();
    for (const otherLink of links) {
      if (otherLink.getAttribute("href") === link.getAttribute("href"))
        sameLinks.push(otherLink);
    }

    return {
      elements: sameLinks,
      index: sameLinks.indexOf(link),
      total: sameLinks.length,
    };
  }

  // open tooltip
  function openTooltip(link) {
    // delete tooltip if it exists, start fresh
    closeTooltip();

    // make tooltip element
    const tooltip = makeTooltip(link);

    // if source couldn't be found and tooltip not made, exit
    if (!tooltip) return;

    // make navbar elements
    const navBar = makeNavBar(link);
    if (navBar) tooltip.firstElementChild.appendChild(navBar);

    // attach tooltip to page
    document.body.appendChild(tooltip);

    // position tooltip
    const position = function () {
      positionTooltip(link);
    };
    position();

    // if tooltip contains images, position again after they've loaded
    const imgs = tooltip.querySelectorAll("img");
    for (const img of imgs) img.addEventListener("load", position);
  }

  // close (delete) tooltip
  function closeTooltip() {
    const tooltip = document.getElementById("tooltip");
    if (tooltip) tooltip.remove();
  }

  // make tooltip
  function makeTooltip(link) {
    // get target element that link points to
    const source = getSource(link);

    // if source can't be found, exit
    if (!source) return;

    // create new tooltip
    const tooltip = document.createElement("div");
    tooltip.id = "tooltip";
    const tooltipContent = document.createElement("div");
    tooltipContent.id = "tooltip_content";
    tooltip.appendChild(tooltipContent);

    // make copy of source node and put in tooltip
    const sourceCopy = makeCopy(source);
    tooltipContent.appendChild(sourceCopy);

    // attach mouse event listeners
    tooltip.addEventListener("click", onTooltipClick);
    tooltip.addEventListener("mousedown", onTooltipClick);
    tooltip.addEventListener("touchstart", onTooltipClick);
    tooltip.addEventListener("mouseleave", onTooltipUnhover);

    // (for interaction with lightbox plugin)
    // transfer click on tooltip copied img to original img
    const sourceImg = source.querySelector("img");
    const sourceCopyImg = sourceCopy.querySelector("img");
    if (sourceImg && sourceCopyImg) {
      const clickImg = function () {
        sourceImg.click();
        closeTooltip();
      };
      sourceCopyImg.addEventListener("click", clickImg);
    }

    return tooltip;
  }

  // make carbon copy of html dom element
  function makeCopy(source) {
    const sourceCopy = source.cloneNode(true);

    // delete elements marked with ignore (eg anchor and jump buttons)
    const deleteFromCopy = sourceCopy.querySelectorAll('[data-ignore="true"]');
    for (const element of deleteFromCopy) element.remove();

    // delete certain element attributes
    const attributes = [
      "id",
      "data-collapsed",
      "data-selected",
      "data-highlighted",
      "data-glow",
      "class",
    ];
    for (const attribute of attributes) {
      sourceCopy.removeAttribute(attribute);
      const elements = sourceCopy.querySelectorAll("[" + attribute + "]");
      for (const element of elements) element.removeAttribute(attribute);
    }

    return sourceCopy;
  }

  // when tooltip is clicked
  function onTooltipClick(event) {
    // when user clicks on tooltip, stop click from transferring
    // outside of tooltip (eg, click off to close tooltip, or eg click
    // off to unhighlight same refs)
    event.stopPropagation();
  }

  // when tooltip is unhovered
  function onTooltipUnhover(event) {
    if (clickClose === "true") return;

    // make sure new mouse/touch/focus no longer over tooltip or any
    // element within it
    const tooltip = document.getElementById("tooltip");
    if (!tooltip) return;
    if (this.contains(event.relatedTarget)) return;

    closeTooltip();
  }

  // make nav bar to go betwen prev/next instances of same reference
  function makeNavBar(link) {
    // find other links to the same source
    const sameLinks = getSameLinks(link);

    // don't show nav bar when singular reference
    if (sameLinks.total <= 1) return;

    // find prev/next links with same target
    const prevLink = getPrevLink(link, sameLinks);
    const nextLink = getNextLink(link, sameLinks);

    // create nav bar
    const navBar = document.createElement("div");
    navBar.id = "tooltip_nav_bar";
    const text = sameLinks.index + 1 + " of " + sameLinks.total;

    // create nav bar prev/next buttons
    const prevButton = document.createElement("button");
    const nextButton = document.createElement("button");
    prevButton.id = "tooltip_prev_button";
    nextButton.id = "tooltip_next_button";
    prevButton.title =
      "Jump to the previous occurence of this item in the document [←]";
    nextButton.title =
      "Jump to the next occurence of this item in the document [→]";
    prevButton.classList.add("icon_button");
    nextButton.classList.add("icon_button");
    prevButton.innerHTML = document.querySelector(".icon_caret_left").innerHTML;
    nextButton.innerHTML =
      document.querySelector(".icon_caret_right").innerHTML;
    navBar.appendChild(prevButton);
    navBar.appendChild(document.createTextNode(text));
    navBar.appendChild(nextButton);

    // attach click listeners to buttons
    prevButton.addEventListener("click", function () {
      onPrevNextClick(link, prevLink);
    });
    nextButton.addEventListener("click", function () {
      onPrevNextClick(link, nextLink);
    });

    return navBar;
  }

  // get previous link with same target
  function getPrevLink(link, sameLinks) {
    if (!sameLinks) sameLinks = getSameLinks(link);
    // wrap index to other side if < 1
    let index;
    if (sameLinks.index - 1 >= 0) index = sameLinks.index - 1;
    else index = sameLinks.total - 1;
    return sameLinks.elements[index];
  }

  // get next link with same target
  function getNextLink(link, sameLinks) {
    if (!sameLinks) sameLinks = getSameLinks(link);
    // wrap index to other side if > total
    let index;
    if (sameLinks.index + 1 <= sameLinks.total - 1) index = sameLinks.index + 1;
    else index = 0;
    return sameLinks.elements[index];
  }

  // get element that is target of link or url hash
  function getSource(link) {
    const hash = link ? link.hash : window.location.hash;
    const id = hash.slice(1);
    let target = document.querySelector('[id="' + id + '"]');
    if (!target) return;

    // if ref or figure, modify target to get expected element
    if (id.indexOf("ref-") === 0) target = target.querySelector(":nth-child(2)");
    else if (id.indexOf("fig:") === 0) target = target.querySelector("figure");

    return target;
  }

  // when prev/next arrow button is clicked
  function onPrevNextClick(link, prevNextLink) {
    if (link && prevNextLink)
      goToElement(prevNextLink, window.innerHeight * 0.5);
  }

  // scroll to and focus element
  function goToElement(element, offset) {
    // expand accordion section if collapsed
    expandElement(element);
    const y =
      getRectInView(element).top -
      getRectInView(document.documentElement).top -
      (offset || 0);
    // trigger any function listening for "onscroll" event
    window.dispatchEvent(new Event("scroll"));
    window.scrollTo(0, y);
    document.activeElement.blur();
    element.focus();
  }

  // determine position to place tooltip based on link position in
  // viewport and tooltip size
  function positionTooltip(link, left, top) {
    const tooltipElement = document.getElementById("tooltip");
    if (!tooltipElement) return;

    // get convenient vars for position/dimensions of
    // link/tooltip/page/view
    link = getRectInPage(link);
    const tooltip = getRectInPage(tooltipElement);
    const view = getRectInPage();

    // horizontal positioning
    if (left)
      // use explicit value
      left = left;
    else if (link.left + tooltip.width < view.right)
      // fit tooltip to right of link
      left = link.left;
    else if (link.right - tooltip.width > view.left)
      // fit tooltip to left of link
      left = link.right - tooltip.width;
    // center tooltip in view
    else left = (view.right - view.left) / 2 - tooltip.width / 2;

    // vertical positioning
    if (top)
      // use explicit value
      top = top;
    else if (link.top - tooltip.height > view.top)
      // fit tooltip above link
      top = link.top - tooltip.height;
    else if (link.bottom + tooltip.height < view.bottom)
      // fit tooltip below link
      top = link.bottom;
    else {
      // center tooltip in view
      top = view.top + view.height / 2 - tooltip.height / 2;
      // nudge off of link to left/right if possible
      if (link.right + tooltip.width < view.right) left = link.right;
      else if (link.left - tooltip.width > view.left)
        left = link.left - tooltip.width;
    }

    tooltipElement.style.left = left + "px";
    tooltipElement.style.top = top + "px";
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
  <!-- modified from: https://fontawesome.com/icons/caret-left -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
    ></path>
  </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
  <!-- modified from: https://fontawesome.com/icons/caret-right -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* tooltip container */
    #tooltip {
      position: absolute;
      width: 50%;
      min-width: 240px;
      max-width: 75%;
      z-index: 1;
    }

    /* tooltip content */
    #tooltip_content {
      margin-bottom: 5px;
      padding: 20px;
      border-radius: 5px;
      border: solid 1px #bdbdbd;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      background: #ffffff;
      overflow-wrap: break-word;
    }

    /* tooltip copy of paragraphs and figures */
    #tooltip_content > p,
    #tooltip_content > figure {
      margin: 0;
      max-height: 320px;
      overflow-y: auto;
    }

    /* tooltip copy of <img> */
    #tooltip_content > figure > img,
    #tooltip_content > figure > svg {
      max-height: 260px;
    }

    /* navigation bar */
    #tooltip_nav_bar {
      margin-top: 10px;
      text-align: center;
    }

    /* navigation bar previous/next buton */
    #tooltip_nav_bar > .icon_button {
      position: relative;
      top: 3px;
    }

    /* navigation bar previous button */
    #tooltip_nav_bar > .icon_button:first-of-type {
      margin-right: 5px;
    }

    /* navigation bar next button */
    #tooltip_nav_bar > .icon_button:last-of-type {
      margin-left: 5px;
    }
  }

  /* always hide tooltip on print */
  @media only print {
    #tooltip {
      display: none;
    }
  }
</style>
<!--
  Analytics Plugin (third-party) 
  
  Copy and paste code from Google Analytics or similar service here.
-->
<!-- 
  Annotations Plugin

  Allows public annotation of the  manuscript. See https://web.hypothes.is/.
-->

<script type="module">
  // configuration
  window.hypothesisConfig = function () {
    return {
      branding: {
        accentColor: "#2196f3",
        appBackgroundColor: "#f8f8f8",
        ctaBackgroundColor: "#f8f8f8",
        ctaTextColor: "#000000",
        selectionFontFamily: "Open Sans, Helvetica, sans serif",
        annotationFontFamily: "Open Sans, Helvetica, sans serif",
      },
    };
  };

  // hypothesis client script
  const embed = "https://hypothes.is/embed.js";
  // hypothesis annotation count query url
  const query = "https://api.hypothes.is/api/search?limit=0&url=";

  // start script
  function start() {
    const button = makeButton();
    document.body.insertBefore(button, document.body.firstChild);
    insertCount(button);
  }

  // make button
  function makeButton() {
    // create button
    const button = document.createElement("button");
    button.id = "hypothesis_button";
    button.innerHTML = document.querySelector(".icon_hypothesis").innerHTML;
    button.title = "Hypothesis annotations";
    button.classList.add("icon_button");

    function onClick(event) {
      onButtonClick(event, button);
    }

    // attach click listeners
    button.addEventListener("click", onClick);

    return button;
  }

  // insert annotations count
  async function insertCount(button) {
    // get annotation count from Hypothesis based on url
    let count = "-";
    try {
      const canonical = document.querySelector('link[rel="canonical"]');
      const location = window.location;
      const url = encodeURIComponent((canonical || location).href);
      const response = await fetch(query + url);
      const json = await response.json();
      count = json.total || "-";
    } catch (error) {
      console.log(error);
    }

    // put count into button
    const counter = document.createElement("span");
    counter.id = "hypothesis_count";
    counter.innerHTML = count;
    button.title = "View " + count + " Hypothesis annotations";
    button.append(counter);
  }

  // when button is clicked
  function onButtonClick(event, button) {
    const script = document.createElement("script");
    script.src = embed;
    document.body.append(script);
    button.remove();
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- hypothesis icon -->

<template class="icon_hypothesis">
  <!-- modified from: https://simpleicons.org/icons/hypothesis.svg / https://git.io/Jf1VB -->
  <svg width="16" height="16" viewBox="0 0 24 24" tabindex="-1">
    <path
      fill="currentColor"
      d="M3.43 0C2.5 0 1.72 .768 1.72 1.72V18.86C1.72 19.8 2.5 20.57 3.43 20.57H9.38L12 24L14.62 20.57H20.57C21.5 20.57 22.29 19.8 22.29 18.86V1.72C22.29 .77 21.5 0 20.57 0H3.43M5.14 3.43H7.72V9.43S8.58 7.72 10.28 7.72C12 7.72 13.74 8.57 13.74 11.24V17.14H11.16V12C11.16 10.61 10.28 10.07 9.43 10.29C8.57 10.5 7.72 11.41 7.72 13.29V17.14H5.14V3.43M18 13.72C18.95 13.72 19.72 14.5 19.72 15.42A1.71 1.71 0 0 1 18 17.13A1.71 1.71 0 0 1 16.29 15.42C16.29 14.5 17.05 13.71 18 13.71Z"
      tabindex="-1"
    ></path>
  </svg>
</template>

<style>
  /* hypothesis activation button */
  #hypothesis_button {
    box-sizing: border-box;
    position: fixed;
    top: 0;
    right: 0;
    width: 60px;
    height: 60px;
    background: #ffffff;
    border-radius: 0;
    border-left: solid 1px #bdbdbd;
    border-bottom: solid 1px #bdbdbd;
    box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
    z-index: 2;
  }

  /* hypothesis button svg */
  #hypothesis_button > svg {
    position: relative;
    top: -4px;
  }

  /* hypothesis annotation count */
  #hypothesis_count {
    position: absolute;
    left: 0;
    right: 0;
    bottom: 5px;
  }

  /* side panel */
  .annotator-frame {
    width: 280px !important;
  }

  /* match highlight color to rest of theme */
  .annotator-highlights-always-on .annotator-hl {
    background-color: #ffeb3b !important;
  }

  /* match focused color to rest of theme */
  .annotator-hl.annotator-hl-focused {
    background-color: #ff8a65 !important;
  }

  /* match bucket bar color to rest of theme */
  .annotator-bucket-bar {
    background: #f5f5f5 !important;
  }

  /* always hide button, toolbar, and tooltip on print */
  @media only print {
    #hypothesis_button {
      display: none;
    }

    .annotator-frame {
      display: none !important;
    }

    hypothesis-adder {
      display: none !important;
    }
  }
</style>
<!-- 
  Mathjax Plugin (third-party) 

  Allows the proper rendering of math/equations written in LaTeX.
  See https://www.mathjax.org/.
-->

<script type="text/x-mathjax-config">
  // configuration
  MathJax.Hub.Config({
    "CommonHTML": { linebreaks: { automatic: true } },
    "HTML-CSS": { linebreaks: { automatic: true } },
    "SVG": { linebreaks: { automatic: true } },
    "fast-preview": { disabled: true }
  });
</script>

<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A=="
  crossorigin="anonymous"
></script>

<style>
  /* mathjax containers */
  .math.display > span:not(.MathJax_Preview) {
    /* turn inline element (no dimensions) into block (allows fixed width and thus scrolling) */
    display: flex !important;
    overflow-x: auto !important;
    overflow-y: hidden !important;
    justify-content: center;
    align-items: center;
    margin: 0 !important;
  }

  /* right click menu */
  .MathJax_Menu {
    border-radius: 5px !important;
    border: solid 1px #bdbdbd !important;
    box-shadow: none !important;
  }

  /* equation auto-number */
  span[id^="eq:"] > span.math.display + span {
    font-weight: 600;
  }

  /* equation */
  span[id^="eq:"] > span.math.display > span {
    /* nudge to make room for equation auto-number and anchor */
    margin-right: 60px !important;
  }
</style>
</body>
</html>
